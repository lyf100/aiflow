---
name: ac:analyze
description: AIFlow ä¸€é”®æ·±åº¦åˆ†æ - åŸºäºMCP Serveräº”é˜¶æ®µAIåˆ†æï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ä»£ç æ´å¯Ÿå’Œå¯è§†åŒ–
---

# ğŸš€ AIFlow v2.1 ä¸€é”®æ·±åº¦åˆ†æï¼ˆä¼˜åŒ–ç‰ˆæç¤ºè¯ï¼‰

## ğŸ­ ä½ çš„è§’è‰²ä¸èŒè´£

ä½ æ˜¯ **AIFlow æ·±åº¦åˆ†ææ‰§è¡Œå™¨**ï¼Œè´Ÿè´£è°ƒç”¨MCPå·¥å…·æ‰§è¡Œäº”é˜¶æ®µä»£ç åˆ†æå¹¶ç”Ÿæˆé«˜è´¨é‡JSONã€‚

**æ ¸å¿ƒèƒ½åŠ›**:
- âœ… è°ƒç”¨MCPå·¥å…·æ‰§è¡Œäº”é˜¶æ®µåˆ†æ
- âœ… å¤„ç†MCPè¿”å›çš„promptå¹¶ç”Ÿæˆç¬¦åˆprotocol.tsçš„JSON
- âœ… ç»´æŠ¤è·¨é˜¶æ®µçš„æ•°æ®å®Œæ•´æ€§
- âœ… ç›‘æ§æ‰§è¡Œè¿›åº¦å¹¶æä¾›å®æ—¶åé¦ˆ

**æ˜ç¡®é™åˆ¶**:
- âŒ ä¸è¦è¯¢é—®ç”¨æˆ·ä»»ä½•ç¡®è®¤é—®é¢˜ï¼ˆå®Œå…¨è‡ªåŠ¨åŒ–ï¼‰
- âŒ ä¸è¦è·³è¿‡ä»»ä½•é˜¶æ®µï¼ˆå³ä½¿é‡åˆ°å›°éš¾ï¼‰
- âŒ ä¸è¦ä¿®æ”¹MCPè¿”å›çš„JSONç»“æ„
- âŒ ä¸è¦åœ¨ä¸­é€”åœæ­¢ï¼ˆé™¤éé‡åˆ°è‡´å‘½é”™è¯¯ï¼‰

---

## âš¡ æ‰§è¡Œå‰å¿…è¯»ï¼ˆå¼ºåˆ¶çº¦æŸï¼‰

```
ğŸš¨ CRITICAL RULES - YOU MUST FOLLOW WITHOUT EXCEPTION:

1. AUTOMATION: è‡ªåŠ¨æ‰§è¡Œå…¨éƒ¨7æ­¥ï¼Œä¸ç­‰å¾…ç”¨æˆ·è¾“å…¥
2. CONTINUATION: æ¯æ­¥å®Œæˆåç«‹å³è¿›å…¥ä¸‹ä¸€æ­¥
3. VALIDATION: è¿›å…¥ä¸‹ä¸€æ­¥å‰éªŒè¯å½“å‰è¾“å‡ºæ˜¯å¦åˆæ³•
4. ERROR RETRY: MCPå·¥å…·å¤±è´¥æ—¶é‡è¯•ä¸€æ¬¡ï¼Œä»å¤±è´¥åˆ™åœæ­¢
5. JSON COMPLETE: ä¼ é€’å®Œæ•´JSONåˆ°ä¸‹ä¸€é˜¶æ®µï¼ˆä¸æˆªæ–­ï¼‰
6. PROGRESS REPORT: æ¯æ­¥æ˜¾ç¤ºç²¾ç¡®çš„è¿›åº¦æ ¼å¼
7. NO QUESTIONS: ä¸è¦é—®"Should I continue?" - ç›´æ¥ç»§ç»­
8. MEMORY REFRESH: æ¯æ­¥å¼€å§‹å‰åˆ·æ–°ä¸Šä¸‹æ–‡è®°å¿†
```

**è´¨é‡æ ‡å‡†å‚è€ƒ**:
- ğŸ“– æ¨ç†æ¨¡æ¿: `.claude/prompts/cot-analysis-template.md`
- ğŸ“– è¾“å‡ºç¤ºä¾‹: `.claude/prompts/few-shot-examples.md`
- ğŸ“– çº¦æŸè§„èŒƒ: `.claude/prompts/constraint-expression-guide.md`

---

## ğŸ¯ æ ¸å¿ƒç†å¿µ

**AIFlow v2.1 = å¯ä¿¡èµ–çš„æ€§èƒ½å¯¼å‘ä¸šåŠ¡åˆ†æå¹³å°**

- âŒ **ä¸å†æ˜¯**: æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çš„æµ…å±‚æ‰«æ
- âœ… **è€Œæ˜¯**: Claude 4.5 æ·±åº¦ç†è§£ä»£ç ä¸šåŠ¡æ„å›¾ + æ–‡æ¡£éªŒè¯
- âŒ **ä¸å†æ˜¯**: 10ç§’å¿«é€Ÿä½†è´¨é‡å·®çš„è¾“å‡º
- âœ… **è€Œæ˜¯**: 40åˆ†é’Ÿ-æ•°å°æ—¶çš„**é«˜è´¨é‡æ·±åº¦æ´å¯Ÿ + æ€§èƒ½é‡åŒ–åˆ†æ**

**ä¸‰å¤§æ ¸å¿ƒå¢å¼º** (v2.1 æ–°ç‰¹æ€§):
- ğŸ“š **æ–‡æ¡£å¯é æ€§è¯„ä¼°**: README vs ä»£ç ä¸€è‡´æ€§éªŒè¯
- â±ï¸ **TCUæ—¶é—´æˆæœ¬æ¨¡å‹**: ç›¸å¯¹æ—¶é—´å•ä½é‡åŒ–æ€§èƒ½
- ğŸ¯ **æ ¸å¿ƒä¸šåŠ¡åœºæ™¯**: è¯†åˆ«3-5ä¸ªæœ€é‡è¦ä¸šåŠ¡æµç¨‹

---

## ğŸ“ ç”¨æ³•

```bash
/ac:analyze <é¡¹ç›®åç§°>
```

**ç¤ºä¾‹**:
```bash
/ac:analyze NewPipe-dev
/ac:analyze test-data
```

---

## ğŸ”„ è‡ªåŠ¨åŒ–æ‰§è¡Œæµç¨‹ï¼ˆ7æ­¥å…¨è‡ªåŠ¨ï¼‰

### ğŸ¬ Step 0: é¡¹ç›®åˆå§‹åŒ– + æ–­ç‚¹æ£€æµ‹ (5ç§’)

**ğŸ§  Memory Refresh**:
```
Goal: Initialize AIFlow analysis for project "<é¡¹ç›®åç§°>"
Check: Detect existing checkpoints for resume capability
Next: Stage 1 - Project Cognition OR Resume from checkpoint
```

**ğŸ” Checkpoint Detection** (å»ºè®®5+7: æ–­ç‚¹ç»­ä¼  + å‹ç¼©æ”¯æŒ):

```bash
# Check for existing compressed checkpoints
Use Read tool to check if files exist:
  - D:/dart/flutter/aiflow/frontend/public/.cache/stage1_checkpoint.json.gz
  - D:/dart/flutter/aiflow/frontend/public/.cache/stage2_checkpoint.json.gz
  - D:/dart/flutter/aiflow/frontend/public/.cache/stage3_checkpoint.json.gz
  - D:/dart/flutter/aiflow/frontend/public/.cache/stage4_checkpoint.json.gz
  - D:/dart/flutter/aiflow/frontend/public/.cache/stage5_checkpoint.json.gz

# Findæœ€æ–°çš„æœ‰æ•ˆcheckpoint
latest_checkpoint = find_latest_valid_checkpoint()
checkpoint_age = current_time - checkpoint.timestamp
```

**ğŸ“Š Checkpoint Resume Logic** (å»ºè®®7: å‹ç¼©æ”¯æŒ):
```
If latest_checkpoint exists AND checkpoint_age < 24 hours:
  Display:
    ```
    ğŸ”„ æ£€æµ‹åˆ°æœªå®Œæˆçš„åˆ†æ
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ğŸ“‚ é¡¹ç›®: <project_name>
    âœ… å·²å®Œæˆ: Stage <X>
    â±ï¸  checkpointæ—¶é—´: <timestamp> (<age> å‰)
    ğŸ’¾ å¯æ¢å¤æ•°æ®å¤§å°: <size> KB (å‹ç¼©å)
    ğŸ“Š å‹ç¼©ç‡: ~70-80% (gzipå‹ç¼©)

    ğŸ¯ é€‰é¡¹:
      1. ä»Stage <X+1>ç»§ç»­ (æ¨è)
      2. é‡æ–°å¼€å§‹å®Œæ•´åˆ†æ
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ```

  Action:
    - Auto-select Option 1 (resume)
    - Load checkpoint data:
      1. Use Read tool to load stage<X>_checkpoint.json.gz
      2. Decompress gzip data using Bash: gunzip -c stage<X>_checkpoint.json.gz
      3. Parse decompressed JSON
    - Validate loaded data integrity
    - Skip to Step <X+1>

Else:
  Continue with normal Step 0 initialization
```

**â¡ï¸ Next**:
- If resumed: è·³è½¬åˆ°å¯¹åº”çš„Step
- If fresh start: è‡ªåŠ¨è¿›å…¥ä¸‹æ–¹çš„é¡¹ç›®åˆå§‹åŒ–æµç¨‹

---

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_init_project tool with:
{
  "project_path": "D:/dart/flutter/aiflow/<é¡¹ç›®åç§°>",
  "project_name": "<é¡¹ç›®åç§°>"
}
```

---

**ğŸ†• Sub-Step 0.1: é¡¹ç›®è§„æ¨¡æ£€æµ‹ + æ™ºèƒ½è¶…æ—¶é…ç½®** (å»ºè®®8: æ™ºèƒ½è¶…æ—¶è°ƒæ•´)

**ç›®æ ‡**: åŸºäºé¡¹ç›®ä»£ç é‡è‡ªåŠ¨è°ƒæ•´å„Stageçš„è¶…æ—¶é…ç½®ï¼Œä¼˜åŒ–åˆ†æä½“éªŒ

**ğŸ“ Project Scale Detection**:
```bash
# Count lines of code (LOC) in project
Use Bash to execute:
cd /d/dart/flutter/aiflow/<é¡¹ç›®åç§°> && find . -type f \( -name "*.js" -o -name "*.ts" -o -name "*.jsx" -o -name "*.tsx" -o -name "*.py" -o -name "*.java" -o -name "*.go" \) -exec wc -l {} + | tail -1 | awk '{print $1}'

# Alternative for Windows (if find not available):
cd /d/dart/flutter/aiflow/<é¡¹ç›®åç§°> && git ls-files | grep -E '\.(js|ts|jsx|tsx|py|java|go)$' | xargs wc -l | tail -1 | awk '{print $1}'
```

**ğŸ“ Dynamic Timeout Calculation Algorithm**:
```python
# Project scale classification
if total_loc < 1000:
    project_scale = "small"
    scale_factor = 0.6  # 60% of base timeout
elif total_loc < 5000:
    project_scale = "medium"
    scale_factor = 1.0  # 100% baseline
elif total_loc < 20000:
    project_scale = "large"
    scale_factor = 2.0  # 200% of base timeout
else:
    project_scale = "extra_large"
    scale_factor = 4.0  # 400% of base timeout

# Calculated timeouts for each stage
stage_timeouts = {
    "stage1": int(20 * scale_factor),  # Base: 20min
    "stage2": int(40 * scale_factor),  # Base: 40min
    "stage3": int(60 * scale_factor),  # Base: 60min
    "stage4": int(80 * scale_factor),  # Base: 80min
    "stage5": int(40 * scale_factor)   # Base: 40min
}
```

**â±ï¸ Adaptive Timeout Configuration Table**:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é¡¹ç›®è§„æ¨¡              | LOCèŒƒå›´        | ç¼©æ”¾å› å­ | Stageè¶…æ—¶é…ç½®
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å°å‹ (Small)         | <1K LOC       | 0.6x    | 12/24/36/48/24 åˆ†é’Ÿ
ä¸­å‹ (Medium)        | 1-5K LOC      | 1.0x    | 20/40/60/80/40 åˆ†é’Ÿ
å¤§å‹ (Large)         | 5-20K LOC     | 2.0x    | 40/80/120/160/80 åˆ†é’Ÿ
è¶…å¤§å‹ (Extra Large)  | >20K LOC      | 4.0x    | 80/160/240/320/160 åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**ğŸ“Š Scale Detection Output**:
```
ğŸ” é¡¹ç›®è§„æ¨¡æ£€æµ‹...
   â€¢ æ€»ä»£ç è¡Œæ•°: <total_loc> LOC
   â€¢ é¡¹ç›®è§„æ¨¡: <project_scale> (<scale_factor>x)
   â€¢ è¶…æ—¶é…ç½®:
     â””â”€ Stage 1: <stage1_timeout> åˆ†é’Ÿ
     â””â”€ Stage 2: <stage2_timeout> åˆ†é’Ÿ
     â””â”€ Stage 3: <stage3_timeout> åˆ†é’Ÿ
     â””â”€ Stage 4: <stage4_timeout> åˆ†é’Ÿ
     â””â”€ Stage 5: <stage5_timeout> åˆ†é’Ÿ

ğŸ’¡ æ™ºèƒ½è°ƒæ•´: åŸºäºé¡¹ç›®è§„æ¨¡è‡ªåŠ¨ä¼˜åŒ–è¶…æ—¶é…ç½®
```

**âœ… Benefits of Intelligent Timeout**:
- **å°å‹é¡¹ç›®**: 60%æ›´å¿«çš„è¶…æ—¶ï¼Œé¿å…ä¸å¿…è¦çš„ç­‰å¾…
- **å¤§å‹é¡¹ç›®**: 400%æ›´é•¿çš„è¶…æ—¶ï¼Œç¡®ä¿å®Œæ•´åˆ†æ
- **åŠ¨æ€é€‚é…**: åŸºäºå®é™…ä»£ç é‡æ™ºèƒ½è°ƒæ•´
- **ç”¨æˆ·ä½“éªŒ**: å‡å°‘è¶…æ—¶å¤±è´¥ï¼Œæå‡æˆåŠŸç‡

---

**ğŸ“Š Required Output**:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æå¯åŠ¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‚ é¡¹ç›®: <é¡¹ç›®åç§°>
ğŸ“ è·¯å¾„: D:/dart/flutter/aiflow/<é¡¹ç›®åç§°>
â±ï¸  é¢„è®¡æ€»è€—æ—¶: 40åˆ†é’Ÿ - 4å°æ—¶

ğŸ¯ æ‰§è¡Œæ¨¡å¼: å…¨è‡ªåŠ¨ 7 æ­¥æµç¨‹
âœ… è´¨é‡ä¼˜å…ˆ: æ·±åº¦åˆ†æ > æ‰§è¡Œé€Ÿåº¦
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 1

---

### ğŸ§  Step 1: Stage 1 - é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (2-20åˆ†é’Ÿ)

**ğŸ§  Memory Refresh**:
```
Step: 1/7 - Stage 1 Project Cognition
Goal: ç†è§£é¡¹ç›®æ¶æ„ã€æŠ€æœ¯æ ˆã€éªŒè¯æ–‡æ¡£å¯é æ€§
Output: stage1_result (ç¬¦åˆStage1Outputæ¥å£)
Next: Stage 2 - Structure Recognition
```

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_stage1_project_cognition tool
```

**â±ï¸ Timeout Configuration** (å»ºè®®4+8: è¶…æ—¶å¤„ç† + æ™ºèƒ½è°ƒæ•´):
```
Max Execution Time: <stage1_timeout> minutes (from Sub-Step 0.1 dynamic calculation)

Dynamic Timeout Examples:
  - Small project (<1K LOC): 12 minutes
  - Medium project (1-5K LOC): 20 minutes
  - Large project (5-20K LOC): 40 minutes
  - Extra Large project (>20K LOC): 80 minutes

Timeout Handler:
  - If timeout occurs after <stage1_timeout>min:
    1. Display warning: "âš ï¸ Stage 1 è¶…æ—¶ (><stage1_timeout>åˆ†é’Ÿ) - å¯èƒ½æ˜¯ç‰¹å¤§å‹é¡¹ç›®"
    2. Offer options:
       a) Retry with +50% timeout (<stage1_timeout * 1.5>min)
       b) Skip Stage 1 with degraded features
       c) Abort analysis
    3. Save partial result to checkpoint if any data collected
```

**ğŸ¯ Your Analysis Tasks**:

MCP Serverè¿”å›promptåï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„åŒ–æµç¨‹åˆ†æï¼š

1. **æ·±åº¦é˜…è¯»é¡¹ç›®ä»£ç **:
   - åˆ†æ package.json/requirements.txt ç­‰é…ç½®
   - è¯†åˆ«æŠ€æœ¯æ ˆç‰ˆæœ¬ã€æ¡†æ¶ã€æ„å»ºå·¥å…·
   - ç†è§£ç›®å½•ç»“æ„å’Œæ¶æ„æ¨¡å¼

2. **ğŸ†• æ–‡æ¡£å¯é æ€§è¯„ä¼°**:
   - å¯¹æ¯” README å£°æ˜ vs å®é™…ä»£ç ä¸€è‡´æ€§
   - è¯„åˆ†: `documentation_reliability.overall_score` (0.0-1.0)
   - é€‰æ‹©ç­–ç•¥: `high_reliability` (â‰¥0.8) / `code_first` (<0.5)
   - ğŸ“– **æ¨ç†æ¨¡æ¿**: `.claude/prompts/cot-analysis-template.md` â†’ Stage 1

3. **ğŸ†• æ ¸å¿ƒä¸šåŠ¡åœºæ™¯è¯†åˆ«**:
   - è¯†åˆ« 3-5 ä¸ªæœ€é‡è¦ä¸šåŠ¡æµç¨‹
   - è¯„ä¼°ä¸šåŠ¡ä»·å€¼ (high/medium/low) å’Œå¤æ‚åº¦ (0.0-1.0)

4. **ç”Ÿæˆå®Œæ•´JSON**:
   - å¿…é¡»ç¬¦åˆ `Stage1Output` æ¥å£
   - åŒ…å«: stage, project_name, tech_stack, architecture, complexity_assessment
   - ğŸ†• åŒ…å«: documentation_reliability, core_business_scenarios
   - ğŸ“– **è´¨é‡ç¤ºä¾‹**: `.claude/prompts/few-shot-examples.md` â†’ Stage 1

**ğŸš¨ Critical Constraints**:
- [ ] `documentation_reliability.overall_score` âˆˆ [0.0, 1.0]
- [ ] `core_business_scenarios.length` âˆˆ [3, 5]
- [ ] `complexity_assessment.score` âˆˆ [0.0, 1.0]
- [ ] JSONé€šè¿‡JSON.parse()éªŒè¯

**âœ… Self-Validation** (Before proceeding):
```
Q: "Identified 3-5 scenarios?" Count = [_] âœ“ In [3,5]?
Q: "Score in [0.0-1.0]?" Score = [_] âœ“ Valid?
Q: "JSON parseable?" âœ“ Passes JSON.parse()?
```

**ğŸ“Š Required Output** (å»ºè®®6: è¿›åº¦å¯è§†åŒ–):
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æè¿›åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20% (Stage 1/5)
Elapsed: <elapsed> | Est. Remaining: <estimated>

âœ… Stage 0: é¡¹ç›®åˆå§‹åŒ– (0.1 min)
ğŸ”„ Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (in progress...)
   â”œâ”€ ğŸ“š éªŒè¯READMEå¯é æ€§... â³
   â”œâ”€ ğŸ¯ è¯†åˆ«æ ¸å¿ƒä¸šåŠ¡åœºæ™¯... â³
   â””â”€ ğŸ—ï¸ åˆ†ææ¶æ„æ¨¡å¼... â³
â³ Stage 2: ç»“æ„è¯†åˆ« (estimated 5-40 min)
â³ Stage 3: è¯­ä¹‰åˆ†æ (estimated 10-60 min)
â³ Stage 4: æ‰§è¡Œæ¨ç† (estimated 15-80 min)
â³ Stage 5: å¹¶å‘æ£€æµ‹ (estimated 5-40 min)

â±ï¸  å½“å‰Stageé¢„è®¡: 2-20åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

å®Œæˆå:
```
âœ… Stage 1 å®Œæˆ
ğŸ“Š ç»“æœ:
   â€¢ æŠ€æœ¯æ ˆ: <è¯­è¨€> + <æ¡†æ¶>
   â€¢ æ¶æ„: <æ¨¡å¼> (ç½®ä¿¡åº¦: <score>)
   â€¢ ğŸ“š æ–‡æ¡£å¯é æ€§: <level> (<score>)
   â€¢ ğŸ¯ æ ¸å¿ƒåœºæ™¯: <count>ä¸ª
```

**âŒ Error Handling**:
- MCPå¤±è´¥: é‡è¯•ä¸€æ¬¡ï¼Œä»å¤±è´¥åˆ™åœæ­¢
- JSONéªŒè¯å¤±è´¥: é‡æ–°ç”Ÿæˆï¼Œå¤±è´¥3æ¬¡åˆ™åœæ­¢

**ğŸ’¾ Save Intermediate Result** (å»ºè®®1+7: éƒ¨åˆ†æˆåŠŸä¿å­˜ + å‹ç¼©):
```bash
# Step 1: Write uncompressed JSON to temporary file
Use Write tool to save:
D:/dart/flutter/aiflow/frontend/public/.cache/stage1_checkpoint.json.tmp

Content: Complete stage1_result JSON

# Step 2: Compress using gzip
Use Bash to execute:
gzip -c D:/dart/flutter/aiflow/frontend/public/.cache/stage1_checkpoint.json.tmp > D:/dart/flutter/aiflow/frontend/public/.cache/stage1_checkpoint.json.gz

# Step 3: Remove temporary uncompressed file
Use Bash to execute:
rm D:/dart/flutter/aiflow/frontend/public/.cache/stage1_checkpoint.json.tmp

Purpose: Enable resume if later stages fail (70-80% disk space reduction)
```

**ğŸ“Š Checkpoint Saved**:
```
ğŸ’¾ Checkpointä¿å­˜: stage1_checkpoint.json.gz
ğŸ“Š å‹ç¼©æ•ˆæœ: åŸå§‹ <original_size> KB â†’ å‹ç¼©å <compressed_size> KB (~<compression_ratio>%)
ğŸ”„ å¯æ¢å¤ç‚¹: Stage 2å¼€å§‹å‰
â±ï¸  å·²è€—æ—¶: <elapsed_time>
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 2

---

### ğŸ—ï¸ Step 2: Stage 2 - ç»“æ„è¯†åˆ« (5-40åˆ†é’Ÿ)

**ğŸ§  Memory Refresh**:
```
Step: 2/7 - Stage 2 Structure Recognition
Previous: Stage 1å¤æ‚åº¦ <score>
Goal: æ„å»ºä»£ç ä¾èµ–å›¾ï¼ˆèŠ‚ç‚¹+è¾¹ï¼‰
Output: stage2_result extending stage1_result
Next: Stage 3 - Semantic Analysis
```

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_stage2_structure_recognition tool with:
{
  "stage1_result": "<Complete Stage 1 JSON>"
}
```

**â±ï¸ Timeout Configuration** (å»ºè®®4+8: è¶…æ—¶å¤„ç† + æ™ºèƒ½è°ƒæ•´):
```
Max Execution Time: <stage2_timeout> minutes (from Sub-Step 0.1 dynamic calculation)

Dynamic Timeout Examples:
  - Small project (<1K LOC): 24 minutes
  - Medium project (1-5K LOC): 40 minutes
  - Large project (5-20K LOC): 80 minutes
  - Extra Large project (>20K LOC): 160 minutes

Timeout Handler:
  - If timeout occurs after <stage2_timeout>min:
    1. Display warning: "âš ï¸ Stage 2 è¶…æ—¶ (><stage2_timeout>åˆ†é’Ÿ) - å¯èƒ½æ˜¯ç‰¹å¤§å‹é¡¹ç›®"
    2. Offer options:
       a) Retry with +50% timeout (<stage2_timeout * 1.5>min)
       b) Skip Stage 2 with degraded features
       c) Abort analysis
    3. Save partial result to checkpoint if any data collected
```

**ğŸ¯ Your Tasks**:
1. æ„å»ºä»£ç èŠ‚ç‚¹æ ‘ï¼ˆç±»ã€å‡½æ•°ã€æ¥å£ã€æ¨¡å—ï¼‰
2. æ„å»ºä¾èµ–å…³ç³»å›¾ï¼ˆcalls, inherits, containsï¼‰
3. ç”Ÿæˆåˆ†ç»„ç­–ç•¥ï¼ˆby_business, by_layer, by_patternï¼‰

**ğŸš¨ Critical Constraints**:
- [ ] JSON extends stage1_result
- [ ] `nodes.length` â‰¥ 10
- [ ] `edges.length` â‰¥ 5
- [ ] All node IDs unique
- [ ] All edge source/target å¼•ç”¨æœ‰æ•ˆèŠ‚ç‚¹

**âœ… Self-Validation**:
```
Q: "At least 10 nodes?" Count = [_]
Q: "All IDs unique?" âœ“ No duplicates?
Q: "All edges valid?" âœ“ References exist?
```

**ğŸ“Š Required Output** (å»ºè®®6: è¿›åº¦å¯è§†åŒ–):
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æè¿›åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40% (Stage 2/5)
Elapsed: <elapsed> | Est. Remaining: <estimated>

âœ… Stage 0: é¡¹ç›®åˆå§‹åŒ– (0.1 min)
âœ… Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (<actual> min)
ğŸ”„ Stage 2: ç»“æ„è¯†åˆ« (in progress...)
   â”œâ”€ ğŸ” æ‰«æä»£ç æ–‡ä»¶... â³
   â”œâ”€ ğŸŒ³ æ„å»ºèŠ‚ç‚¹æ ‘... â³
   â””â”€ ğŸ”— åˆ†æä¾èµ–å…³ç³»... â³
â³ Stage 3: è¯­ä¹‰åˆ†æ (estimated 10-60 min)
â³ Stage 4: æ‰§è¡Œæ¨ç† (estimated 15-80 min)
â³ Stage 5: å¹¶å‘æ£€æµ‹ (estimated 5-40 min)

â±ï¸  å½“å‰Stageé¢„è®¡: 5-40åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

å®Œæˆå:
```
âœ… Stage 2 å®Œæˆ
ğŸ“Š ç»“æœ:
   â€¢ æ€»èŠ‚ç‚¹: <count>
   â€¢ æ€»è¾¹: <count>
   â€¢ æœ€å¤§æ·±åº¦: <depth>
```

**ğŸ’¾ Save Intermediate Result** (å»ºè®®1+7: éƒ¨åˆ†æˆåŠŸä¿å­˜ + å‹ç¼©):
```bash
# Step 1: Write uncompressed JSON to temporary file
Use Write tool to save:
D:/dart/flutter/aiflow/frontend/public/.cache/stage2_checkpoint.json.tmp

Content: Complete stage2_result JSON (extending stage1_result)

# Step 2: Compress using gzip
Use Bash to execute:
gzip -c D:/dart/flutter/aiflow/frontend/public/.cache/stage2_checkpoint.json.tmp > D:/dart/flutter/aiflow/frontend/public/.cache/stage2_checkpoint.json.gz

# Step 3: Remove temporary uncompressed file
Use Bash to execute:
rm D:/dart/flutter/aiflow/frontend/public/.cache/stage2_checkpoint.json.tmp

Purpose: Enable resume if later stages fail (70-80% disk space reduction)
```

**ğŸ“Š Checkpoint Saved**:
```
ğŸ’¾ Checkpointä¿å­˜: stage2_checkpoint.json.gz
ğŸ“Š å‹ç¼©æ•ˆæœ: åŸå§‹ <original_size> KB â†’ å‹ç¼©å <compressed_size> KB (~<compression_ratio>%)
ğŸ”„ å¯æ¢å¤ç‚¹: Stage 3å¼€å§‹å‰
â±ï¸  å·²è€—æ—¶: <elapsed_time>
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 3

---

### ğŸ” Step 3: Stage 3 - è¯­ä¹‰åˆ†æ (10-60åˆ†é’Ÿ)

**ğŸ§  Memory Refresh**:
```
Step: 3/7 - Stage 3 Semantic Analysis
Previous: æ„å»ºäº† <nodes>ä¸ªèŠ‚ç‚¹, <edges>æ¡è¾¹
Goal: è¯†åˆ«ä¸šåŠ¡å¯ç†è§£çš„å¯åŠ¨æŒ‰é’®ï¼ˆmacro/microï¼‰
Output: stage3_result with launch_buttons
Next: Stage 4 - Execution Inference
```

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_stage3_semantic_analysis tool with:
{
  "stage2_result": "<Complete Stage 2 JSON>"
}
```

**â±ï¸ Timeout Configuration** (å»ºè®®4+8: è¶…æ—¶å¤„ç† + æ™ºèƒ½è°ƒæ•´):
```
Max Execution Time: <stage3_timeout> minutes (from Sub-Step 0.1 dynamic calculation)

Dynamic Timeout Examples:
  - Small project (<1K LOC): 36 minutes
  - Medium project (1-5K LOC): 60 minutes
  - Large project (5-20K LOC): 120 minutes
  - Extra Large project (>20K LOC): 240 minutes

Timeout Handler:
  - If timeout occurs after <stage3_timeout>min:
    1. Display warning: "âš ï¸ Stage 3 è¶…æ—¶ (><stage3_timeout>åˆ†é’Ÿ) - å¯èƒ½æ˜¯ç‰¹å¤§å‹é¡¹ç›®"
    2. Offer options:
       a) Retry with +50% timeout (<stage3_timeout * 1.5>min)
       b) Skip Stage 3 with degraded features
       c) Abort analysis
    3. Save partial result to checkpoint if any data collected
```

**ğŸ¯ Your Tasks**:
1. **è¯†åˆ«Launch Buttons**:
   - Macro (ç³»ç»Ÿçº§): "ç”¨æˆ·ç™»å½•æµç¨‹"
   - Micro (ç»„ä»¶çº§): "éªŒè¯é‚®ç®±"
2. **è¯­ä¹‰åŒ–å‘½å**: ä½¿ç”¨ä¸šåŠ¡è¯­è¨€ï¼ŒéæŠ€æœ¯æœ¯è¯­
3. **å»ºç«‹å±‚çº§**: parent_button_id, child_button_ids
4. **å…ƒæ•°æ®æ ‡æ³¨**: business_value, estimated_duration_ms

**ğŸš¨ Critical Constraints**:
- [ ] è‡³å°‘5ä¸ªlaunch buttons
- [ ] è‡³å°‘1ä¸ªmacro button
- [ ] Button namesä¸šåŠ¡å‹å¥½ï¼ˆéæŠ€æœ¯æœ¯è¯­ï¼‰
- [ ] Hierarchyæ— å¾ªç¯å¼•ç”¨
- [ ] All related_node_idsæœ‰æ•ˆ

**âœ… Self-Validation**:
```
Q: "At least 5 buttons?" Count = [_]
Q: "Names business-friendly?" âœ“ Not technical?
Q: "No circular refs?" âœ“ Valid hierarchy?
```

**ğŸ“Š Required Output** (å»ºè®®6: è¿›åº¦å¯è§†åŒ–):
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æè¿›åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% (Stage 3/5)
Elapsed: <elapsed> | Est. Remaining: <estimated>

âœ… Stage 0: é¡¹ç›®åˆå§‹åŒ– (0.1 min)
âœ… Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (<actual1> min)
âœ… Stage 2: ç»“æ„è¯†åˆ« (<actual2> min)
ğŸ”„ Stage 3: è¯­ä¹‰åˆ†æ (in progress...)
   â”œâ”€ ğŸ¯ è¯†åˆ«ä¸šåŠ¡åŠŸèƒ½å•å…ƒ... â³
   â”œâ”€ ğŸ”˜ ç”Ÿæˆå¯åŠ¨æŒ‰é’®... â³
   â””â”€ ğŸŒ³ æ„å»ºæŒ‰é’®å±‚çº§... â³
â³ Stage 4: æ‰§è¡Œæ¨ç† (estimated 15-80 min)
â³ Stage 5: å¹¶å‘æ£€æµ‹ (estimated 5-40 min)

â±ï¸  å½“å‰Stageé¢„è®¡: 10-60åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

å®Œæˆå:
```
âœ… Stage 3 å®Œæˆ
ğŸ“Š ç»“æœ:
   â€¢ æ€»æŒ‰é’®: <count>
   â€¢ Macro: <count>, Micro: <count>
   â€¢ åµŒå¥—æ·±åº¦: <depth>
```

**ğŸ’¾ Save Intermediate Result** (å»ºè®®1+7: éƒ¨åˆ†æˆåŠŸä¿å­˜ + å‹ç¼©):
```bash
# Step 1: Write uncompressed JSON to temporary file
Use Write tool to save:
D:/dart/flutter/aiflow/frontend/public/.cache/stage3_checkpoint.json.tmp

Content: Complete stage3_result JSON

# Step 2: Compress using gzip
Use Bash to execute:
gzip -c D:/dart/flutter/aiflow/frontend/public/.cache/stage3_checkpoint.json.tmp > D:/dart/flutter/aiflow/frontend/public/.cache/stage3_checkpoint.json.gz

# Step 3: Remove temporary uncompressed file
Use Bash to execute:
rm D:/dart/flutter/aiflow/frontend/public/.cache/stage3_checkpoint.json.tmp

Purpose: Enable resume if later stages fail (70-80% disk space reduction)
```

**ğŸ“Š Checkpoint Saved**:
```
ğŸ’¾ Checkpointä¿å­˜: stage3_checkpoint.json.gz
ğŸ“Š å‹ç¼©æ•ˆæœ: åŸå§‹ <original_size> KB â†’ å‹ç¼©å <compressed_size> KB (~<compression_ratio>%)
ğŸ”„ å¯æ¢å¤ç‚¹: Stage 4å¼€å§‹å‰
â±ï¸  å·²è€—æ—¶: <elapsed_time>
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 4

---

### âš¡ Step 4: Stage 4 - æ‰§è¡Œæ¨ç† + æ€§èƒ½é‡åŒ– (15-80åˆ†é’Ÿ)

**ğŸ§  Memory Refresh**:
```
Step: 4/7 - Stage 4 Execution Inference + Performance
Previous: ç”Ÿæˆäº† <buttons>ä¸ªå¯åŠ¨æŒ‰é’®
Goal: æ¨ç†æ‰§è¡Œæµç¨‹å¹¶é‡åŒ–TCUæ—¶é—´æˆæœ¬
Output: stage4_result with flowchart, timeline_estimation
Next: Stage 5 - Concurrency Detection
```

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_stage4_execution_inference tool with:
{
  "stage3_result": "<Complete Stage 3 JSON>"
}
```

**â±ï¸ Timeout Configuration** (å»ºè®®4+8: è¶…æ—¶å¤„ç† + æ™ºèƒ½è°ƒæ•´):
```
Max Execution Time: <stage4_timeout> minutes (from Sub-Step 0.1 dynamic calculation)

Dynamic Timeout Examples:
  - Small project (<1K LOC): 48 minutes
  - Medium project (1-5K LOC): 80 minutes
  - Large project (5-20K LOC): 160 minutes
  - Extra Large project (>20K LOC): 320 minutes

Timeout Handler:
  - If timeout occurs after <stage4_timeout>min:
    1. Display warning: "âš ï¸ Stage 4 è¶…æ—¶ (><stage4_timeout>åˆ†é’Ÿ) - å¯èƒ½æ˜¯ç‰¹å¤§å‹é¡¹ç›®"
    2. Offer options:
       a) Retry with +50% timeout (<stage4_timeout * 1.5>min)
       b) Skip Stage 4 with degraded features
       c) Abort analysis
    3. Save partial result to checkpoint if any data collected
```

**ğŸ¯ Your Tasks**:

1. **æ¨ç†æ‰§è¡Œæµç¨‹**:
   - ä¸ºæ¯ä¸ªtraceable unitç”Ÿæˆflowchart
   - æ ‡è®°èŠ‚ç‚¹ç±»å‹: start, end, process, decision, fork, join

2. **ğŸ†• TCUæ—¶é—´æˆæœ¬ä¼°ç®—**:
   - **CPU**: 1-20 TCU
   - **I/O**: 50-800 TCU
   - **DB**: 100-500 TCU
   - **Network**: 200-800 TCU
   - ğŸ“– **å‚è€ƒ**: `.claude/prompts/cot-analysis-template.md` â†’ TCUä¼°ç®—

3. **ğŸ†• å¹¶å‘å…³ç³»æ ‡è®°**:
   - `parallel_group`: å¯å¹¶è¡Œæ“ä½œç»„
   - `blocks_on`: ä¾èµ–çš„å‰ç½®äº‹ä»¶
   - è®¡ç®— `critical_path_tcu`

4. **ğŸ†• æ€§èƒ½æ´å¯Ÿ**:
   - ç“¶é¢ˆè¯†åˆ«: TCUæˆæœ¬ >500
   - å¹¶è¡Œæœºä¼š: å¯å¹¶è¡Œä½†ä¸²è¡Œçš„æ“ä½œ
   - ä¼˜åŒ–æ”¶ç›Š: `potential_saving_tcu`

**ğŸš¨ Critical Constraints**:
- [ ] æ¯ä¸ªtraceable unitæœ‰flowchart
- [ ] æ‰€æœ‰TCUåœ¨æœ‰æ•ˆèŒƒå›´å†…
- [ ] `timeline_estimation.total_tcu` å·²è®¡ç®—
- [ ] è‡³å°‘è¯†åˆ«1ä¸ªç“¶é¢ˆ
- [ ] è‡³å°‘æ‰¾åˆ°1ä¸ªå¹¶è¡Œä¼˜åŒ–æœºä¼š

**âœ… Self-Validation**:
```
Q: "TCU values valid?" âœ“ In correct ranges?
Q: "At least 1 bottleneck?" Count = [_]
Q: "Timeline calculated?" âœ“ total_tcu present?
```

**ğŸ“Š Required Output** (å»ºè®®6: è¿›åº¦å¯è§†åŒ–):
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æè¿›åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 80% (Stage 4/5)
Elapsed: <elapsed> | Est. Remaining: <estimated>

âœ… Stage 0: é¡¹ç›®åˆå§‹åŒ– (0.1 min)
âœ… Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (<actual1> min)
âœ… Stage 2: ç»“æ„è¯†åˆ« (<actual2> min)
âœ… Stage 3: è¯­ä¹‰åˆ†æ (<actual3> min)
ğŸ”„ Stage 4: æ‰§è¡Œæ¨ç† + æ€§èƒ½é‡åŒ– (in progress...)
   â”œâ”€ ğŸ”€ æ¨ç†æ‰§è¡Œæµç¨‹... â³
   â”œâ”€ â±ï¸ ä¼°ç®—TCUæˆæœ¬... â³
   â”œâ”€ ğŸ” è¯†åˆ«å¹¶å‘å…³ç³»... â³
   â””â”€ ğŸ¯ å®šä½æ€§èƒ½ç“¶é¢ˆ... â³
â³ Stage 5: å¹¶å‘æ£€æµ‹ (estimated 5-40 min)

â±ï¸  å½“å‰Stageé¢„è®¡: 15-80åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

å®Œæˆå:
```
âœ… Stage 4 å®Œæˆ
ğŸ“Š ç»“æœ:
   â€¢ â±ï¸ æ€»TCU: <total_tcu>
   â€¢ ğŸ¯ å…³é”®è·¯å¾„: <critical_path_tcu>
   â€¢ ğŸ” ç“¶é¢ˆ: <count>ä¸ª
   â€¢ ğŸ’¡ ä¼˜åŒ–æœºä¼š: <count>ä¸ª
```

**ğŸ’¾ Save Intermediate Result** (å»ºè®®1+7: éƒ¨åˆ†æˆåŠŸä¿å­˜ + å‹ç¼©):
```bash
# Step 1: Write uncompressed JSON to temporary file
Use Write tool to save:
D:/dart/flutter/aiflow/frontend/public/.cache/stage4_checkpoint.json.tmp

Content: Complete stage4_result JSON

# Step 2: Compress using gzip
Use Bash to execute:
gzip -c D:/dart/flutter/aiflow/frontend/public/.cache/stage4_checkpoint.json.tmp > D:/dart/flutter/aiflow/frontend/public/.cache/stage4_checkpoint.json.gz

# Step 3: Remove temporary uncompressed file
Use Bash to execute:
rm D:/dart/flutter/aiflow/frontend/public/.cache/stage4_checkpoint.json.tmp

Purpose: Enable resume if later stages fail (70-80% disk space reduction)
```

**ğŸ“Š Checkpoint Saved**:
```
ğŸ’¾ Checkpointä¿å­˜: stage4_checkpoint.json.gz
ğŸ“Š å‹ç¼©æ•ˆæœ: åŸå§‹ <original_size> KB â†’ å‹ç¼©å <compressed_size> KB (~<compression_ratio>%)
ğŸ”„ å¯æ¢å¤ç‚¹: Stage 5å¼€å§‹å‰
â±ï¸  å·²è€—æ—¶: <elapsed_time>
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 5

---

### ğŸ”€ Step 5: Stage 5 - å¹¶å‘æ£€æµ‹ (5-40åˆ†é’Ÿ)

**ğŸ§  Memory Refresh**:
```
Step: 5/7 - Stage 5 Concurrency Detection
Previous: æ€»TCU <total>, å…³é”®è·¯å¾„ <critical>
Goal: æ£€æµ‹å¹¶å‘é—®é¢˜ï¼ˆdeadlocks, data racesï¼‰
Output: stage5_result with issues, suggestions
Next: Step 6 - Combine Results
```

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_stage5_concurrency_detection tool with:
{
  "stage4_result": "<Complete Stage 4 JSON>"
}
```

**â±ï¸ Timeout Configuration** (å»ºè®®4+8: è¶…æ—¶å¤„ç† + æ™ºèƒ½è°ƒæ•´):
```
Max Execution Time: <stage5_timeout> minutes (from Sub-Step 0.1 dynamic calculation)

Dynamic Timeout Examples:
  - Small project (<1K LOC): 24 minutes
  - Medium project (1-5K LOC): 40 minutes
  - Large project (5-20K LOC): 80 minutes
  - Extra Large project (>20K LOC): 160 minutes

Timeout Handler:
  - If timeout occurs after <stage5_timeout>min:
    1. Display warning: "âš ï¸ Stage 5 è¶…æ—¶ (><stage5_timeout>åˆ†é’Ÿ) - å¯èƒ½æ˜¯ç‰¹å¤§å‹é¡¹ç›®"
    2. Offer options:
       a) Retry with +50% timeout (<stage5_timeout * 1.5>min)
       b) Skip Stage 5 with degraded features
       c) Abort analysis
    3. Save partial result to checkpoint if any data collected
```

**ğŸ¯ Your Tasks**:
1. æ£€æµ‹å¹¶å‘æœºåˆ¶ï¼ˆasync/await, locks, threadsï¼‰
2. è¯†åˆ«åŒæ­¥ç‚¹å¹¶è¯„ä¼°æ­»é”é£é™©
3. æ£€æŸ¥å…±äº«èµ„æºçš„çº¿ç¨‹å®‰å…¨æ€§
4. ç”Ÿæˆé—®é¢˜æŠ¥å‘Šï¼ˆseverityåˆ†ç±»ï¼‰
5. æä¾›ä¼˜åŒ–å»ºè®®

**ğŸš¨ Critical Constraints**:
- [ ] è¯†åˆ«æ‰€æœ‰å¹¶å‘æœºåˆ¶
- [ ] è¯„ä¼°æ‰€æœ‰åŒæ­¥ç‚¹çš„æ­»é”é£é™©
- [ ] æ£€æŸ¥æ‰€æœ‰å…±äº«èµ„æº
- [ ] é—®é¢˜æŒ‰severityåˆ†ç±»
- [ ] æä¾›å¯æ“ä½œçš„å»ºè®®

**âœ… Self-Validation**:
```
Q: "All mechanisms found?" âœ“ Complete?
Q: "Issues classified?" âœ“ Has severity?
Q: "Suggestions actionable?" âœ“ Concrete?
```

**ğŸ“Š Required Output** (å»ºè®®6: è¿›åº¦å¯è§†åŒ–):
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ AIFlow v2.1 æ·±åº¦åˆ†æè¿›åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (Stage 5/5)
Elapsed: <elapsed> | Est. Remaining: <estimated>

âœ… Stage 0: é¡¹ç›®åˆå§‹åŒ– (0.1 min)
âœ… Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯ (<actual1> min)
âœ… Stage 2: ç»“æ„è¯†åˆ« (<actual2> min)
âœ… Stage 3: è¯­ä¹‰åˆ†æ (<actual3> min)
âœ… Stage 4: æ‰§è¡Œæ¨ç† + æ€§èƒ½é‡åŒ– (<actual4> min)
ğŸ”„ Stage 5: å¹¶å‘æ£€æµ‹ (in progress...)
   â”œâ”€ ğŸ” æ£€æµ‹å¹¶å‘æœºåˆ¶... â³
   â”œâ”€ âš ï¸ è¯†åˆ«æ­»é”é£é™©... â³
   â””â”€ ğŸ›¡ï¸ æ£€æŸ¥çº¿ç¨‹å®‰å…¨... â³

â±ï¸  å½“å‰Stageé¢„è®¡: 5-40åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

å®Œæˆå:
```
âœ… Stage 5 å®Œæˆ
ğŸ“Š ç»“æœ:
   â€¢ å¹¶å‘æœºåˆ¶: <count>ç§
   â€¢ åŒæ­¥ç‚¹: <count>ä¸ª
   â€¢ é—®é¢˜: <count>ä¸ª (Critical: <c>, High: <h>)
   â€¢ çº¿ç¨‹å®‰å…¨: <percent>%
```

**ğŸ’¾ Save Intermediate Result** (å»ºè®®1+7: éƒ¨åˆ†æˆåŠŸä¿å­˜ + å‹ç¼©):
```bash
# Step 1: Write uncompressed JSON to temporary file
Use Write tool to save:
D:/dart/flutter/aiflow/frontend/public/.cache/stage5_checkpoint.json.tmp

Content: Complete stage5_result JSON

# Step 2: Compress using gzip
Use Bash to execute:
gzip -c D:/dart/flutter/aiflow/frontend/public/.cache/stage5_checkpoint.json.tmp > D:/dart/flutter/aiflow/frontend/public/.cache/stage5_checkpoint.json.gz

# Step 3: Remove temporary uncompressed file
Use Bash to execute:
rm D:/dart/flutter/aiflow/frontend/public/.cache/stage5_checkpoint.json.tmp

Purpose: Final checkpoint before result compilation (70-80% disk space reduction)
```

**ğŸ“Š Checkpoint Saved**:
```
ğŸ’¾ Checkpointä¿å­˜: stage5_checkpoint.json.gz
ğŸ“Š å‹ç¼©æ•ˆæœ: åŸå§‹ <original_size> KB â†’ å‹ç¼©å <compressed_size> KB (~<compression_ratio>%)
ğŸ”„ å¯æ¢å¤ç‚¹: Step 6å¼€å§‹å‰
â±ï¸  å·²è€—æ—¶: <elapsed_time>
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 6

---

### ğŸ“¦ Step 6: åˆå¹¶ç»“æœ + ç”Ÿæˆå‰ç«¯æ•°æ® (10ç§’)

**ğŸ§  Memory Refresh**:
```
Step: 6/7 - Combine Results & Generate Frontend Data
Previous: å®Œæˆå…¨éƒ¨5ä¸ªåˆ†æé˜¶æ®µ
Goal:
  1. åˆ›å»ºæ‘˜è¦JSON: frontend/public/<project>-analysis.json
  2. ç”Ÿæˆå‰ç«¯JSON: frontend/public/analysis.json (å‰ç«¯åŠ è½½)
Output: ä¸¤ä¸ªJSONæ–‡ä»¶
Next: Step 7 - Launch Frontend
```

**ğŸ¯ Sub-Step 6.1: åˆ›å»ºæ‘˜è¦JSON**

**ğŸ“ MCP Tool Call**:
```javascript
Use the aiflow_combine_results tool with:
{
  "stage5_result": "<Complete Stage 5 JSON>",
  "output_path": "frontend/public/<é¡¹ç›®åç§°>-analysis.json"
}
```

**ğŸ“Š Progress Output**:
```
âœ… Stage 5 å®Œæˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¦ Step 6/7: åˆå¹¶ç»“æœ + ç”Ÿæˆå‰ç«¯æ•°æ®
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â³ Sub-Step 6.1: åˆ›å»ºæ‘˜è¦JSON...
ğŸ’¾ å†™å…¥æ–‡ä»¶: <é¡¹ç›®åç§°>-analysis.json...
âœ… éªŒè¯JSON...
```

---

**ğŸ¯ Sub-Step 6.2: ç”Ÿæˆå‰ç«¯å…¼å®¹JSON**

**ç›®æ ‡**: åˆ›å»º `analysis.json` ä¾›å‰ç«¯è‡ªåŠ¨åŠ è½½

**å‰ç«¯æ•°æ®æ ¼å¼è¦æ±‚** (frontend/src/App.tsx expects):
```typescript
{
  "metadata": {
    "project_name": string,
    "project_type": string,
    "analysis_version": string,
    "protocol_version": string,
    "stages_completed": string[],
    "stages_skipped": string[],
    "analysis_timestamp": string,
    "documentation_reliability": {...},  // From Stage 1
    "tech_stack": {...},                 // From Stage 1
    "architecture": {...},               // From Stage 1
    "complexity_assessment": {...},      // From Stage 1
    "core_business_scenarios": [...]     // From Stage 1
  },
  "code_structure": {
    "nodes": [...],                      // From Stage 2 - COMPLETE ARRAY
    "edges": [...],                      // From Stage 2 - COMPLETE ARRAY
    "grouping_strategy": {...},          // From Stage 2
    "analysis_metrics": {...}            // From Stage 2
  },
  "execution_traces": [...],             // From Stage 4 - COMPLETE ARRAY
  "tcu_summary": {...},                  // From Stage 4
  "concurrency_analysis": {              // From Stage 5
    "concurrency_mechanisms": [...],
    "synchronization_points": [...],
    "shared_resources": [...],
    "detected_issues": [...],
    "concurrency_metrics": {...}
  },
  "aiflow_v2_1_features": {...}
}
```

**ğŸ“ Your Tasks**:

1. **Extract Data from Stage Results**:
   - From `stage1_result`: metadata fields, tech_stack, architecture, core_business_scenarios
   - From `stage2_result`: code_structure.nodes[], code_structure.edges[], grouping_strategy
   - From `stage3_result`: launch_buttons (optional for frontend)
   - From `stage4_result`: execution_traces[], tcu_summary, performance_insights
   - From `stage5_result`: concurrency_analysis complete object

2. **ğŸ†• Data Extraction Verification** (å»ºè®®2: æ•°æ®æå–éªŒè¯):
   ```
   // Pseudo-code validation - Execute mentally before constructing JSON

   // Extract nodes[] from Stage 2
   const nodes = stage2_result.stage2_structure_recognition.code_structure.nodes;
   assert(Array.isArray(nodes), "nodes must be array");
   assert(nodes.length >= 10, "nodes array incomplete - need full array from Stage 2");

   // Extract edges[] from Stage 2
   const edges = stage2_result.stage2_structure_recognition.code_structure.edges;
   assert(Array.isArray(edges), "edges must be array");
   assert(edges.length >= 5, "edges array incomplete - need full array from Stage 2");

   // Extract execution_traces from Stage 4
   const traces = stage4_result.stage4_execution_inference.execution_traces;
   assert(Array.isArray(traces), "execution_traces must be array");
   assert(traces.length > 0, "execution_traces array empty");

   // Extract metadata from Stage 1
   const metadata = stage1_result.stage1_project_cognition;
   assert(metadata.tech_stack !== undefined, "tech_stack missing");
   assert(metadata.core_business_scenarios.length >= 3, "core_business_scenarios incomplete");
   ```

3. **Construct Frontend JSON**:
   ```json
   {
     "metadata": {
       "project_name": "<from stage1>",
       "project_type": "<from stage1>",
       "analysis_version": "2.1.0",
       "protocol_version": "2.1.0",
       "stages_completed": ["stage1_project_cognition", "stage2_structure_recognition", ...],
       "stages_skipped": [],
       "analysis_timestamp": "<ISO 8601>",

       "documentation_reliability": {...},  // Copy from stage1
       "tech_stack": {...},                 // Copy from stage1
       "architecture": {...},               // Copy from stage1
       "complexity_assessment": {...},      // Copy from stage1
       "core_business_scenarios": [...]     // Copy from stage1
     },
     "code_structure": {
       "nodes": [...],                      // FULL array from stage2
       "edges": [...],                      // FULL array from stage2
       "grouping_strategy": {...},          // Copy from stage2
       "analysis_metrics": {...}            // Copy from stage2
     },
     "execution_traces": [...],             // FULL array from stage4
     "tcu_summary": {...},                  // Copy from stage4
     "concurrency_analysis": {              // FULL object from stage5
       "concurrency_mechanisms": [...],
       "synchronization_points": [...],
       "shared_resources": [...],
       "detected_issues": [...],
       "concurrency_metrics": {...}
     },
     "aiflow_v2_1_features": {
       "documentation_reliability_enabled": true,
       "tcu_time_model_enabled": true,
       "core_business_scenarios_enabled": true,
       "performance_insights_enabled": true,
       "concurrency_detection_enabled": true
     }
   }
   ```

3. **Write Frontend JSON**:
   ```bash
   Use Write tool to create:
   D:/dart/flutter/aiflow/frontend/public/analysis.json
   ```

**ğŸš¨ Critical Constraints**:
- [ ] `code_structure.nodes` must be COMPLETE array from Stage 2 (NOT summary)
- [ ] `code_structure.edges` must be COMPLETE array from Stage 2 (NOT summary)
- [ ] `execution_traces` must be COMPLETE array from Stage 4
- [ ] All metadata fields present and valid
- [ ] JSON passes JSON.parse() validation
- [ ] File size reasonable (typically 50-500KB for complete data)

**âœ… Self-Validation**:
```
Q: "nodes[] is complete array?" âœ“ Length > 10?
Q: "edges[] is complete array?" âœ“ Length > 5?
Q: "execution_traces[] present?" âœ“ Not empty?
Q: "File created?" âœ“ Exists at frontend/public/analysis.json?
```

**ğŸ“Š Progress Output**:
```
â³ Sub-Step 6.2: ç”Ÿæˆå‰ç«¯å…¼å®¹JSON...
ğŸ“‹ æå–Stage 1-5å®Œæ•´æ•°æ®...
ğŸ”§ æ„å»ºå‰ç«¯æ ¼å¼...
   â€¢ metadata: âœ…
   â€¢ code_structure.nodes: <count>ä¸ª âœ…
   â€¢ code_structure.edges: <count>æ¡ âœ…
   â€¢ execution_traces: <count>ä¸ª âœ…
   â€¢ concurrency_analysis: âœ…
ğŸ’¾ å†™å…¥æ–‡ä»¶: frontend/public/analysis.json...
âœ… éªŒè¯JSONæ ¼å¼...
```

---

**ğŸ¯ Sub-Step 6.3: è·¨Stageæ•°æ®ä¸€è‡´æ€§éªŒè¯** (å»ºè®®3: ä¸€è‡´æ€§éªŒè¯)

**ç›®æ ‡**: ç¡®ä¿æ‰€æœ‰Stageé—´çš„å¼•ç”¨å®Œæ•´æ€§å’Œæ•°æ®ä¸€è‡´æ€§

**ğŸ” Consistency Checks**:

1. **Node IDä¸€è‡´æ€§éªŒè¯**:
   ```
   // Verify all edge references point to valid nodes
   for each edge in code_structure.edges:
     assert(edge.source exists in code_structure.nodes, `Edge ${edge.id} has invalid source`)
     assert(edge.target exists in code_structure.nodes, `Edge ${edge.id} has invalid target`)

   // Verify all flowchart node references exist
   for each trace in execution_traces:
     for each flowchart_node in trace.flowchart.nodes:
       if flowchart_node.related_node_ids:
         for each related_id in flowchart_node.related_node_ids:
           assert(related_id exists in code_structure.nodes, `Flowchart node references invalid code node`)
   ```

2. **Business Scenarioä¸€è‡´æ€§**:
   ```
   // Check if Stage 1 scenarios are covered in Stage 3 launch buttons
   const stage1_scenarios = metadata.core_business_scenarios;
   const stage3_buttons = stage3_result.stage3_semantic_analysis.launch_buttons;

   for each scenario in stage1_scenarios:
     scenario_covered = stage3_buttons.some(button =>
       button.name.includes(scenario.name) OR
       button.business_value === scenario.business_value
     );
     if (!scenario_covered):
       warn(`Business scenario "${scenario.name}" not found in launch buttons`)
   ```

3. **Complexityä¸€è‡´æ€§**:
   ```
   // Verify Stage 1 complexity aligns with Stage 2 metrics
   const stage1_complexity = metadata.complexity_assessment.score;
   const stage2_depth = code_structure.analysis_metrics.max_depth;
   const stage2_edges = code_structure.edges.length;

   // High complexity should correlate with deep hierarchies
   if (stage1_complexity > 0.7 AND stage2_depth < 3):
     warn("High complexity but shallow code structure - potential mismatch")

   if (stage1_complexity < 0.3 AND stage2_edges > 100):
     warn("Low complexity but many dependencies - potential mismatch")
   ```

**ğŸ“Š Validation Output**:
```
ğŸ” è·¨Stageä¸€è‡´æ€§éªŒè¯...
   â€¢ Node IDå¼•ç”¨: <valid_count>/<total_count> âœ…
   â€¢ ä¸šåŠ¡åœºæ™¯è¦†ç›–: <coverage>% âœ…
   â€¢ å¤æ‚åº¦ä¸€è‡´æ€§: âœ… åˆç†
âš ï¸  å‘ç° <count> ä¸ªè­¦å‘Š (éè‡´å‘½ï¼Œå¯ç»§ç»­)
```

---

**ğŸ¯ Sub-Step 6.4: åˆ†æè´¨é‡è¯„åˆ†** (å»ºè®®9: è´¨é‡è¯„åˆ†ç³»ç»Ÿ)

**ç›®æ ‡**: ä¸ºæ•´ä¸ªåˆ†æè¿‡ç¨‹æä¾›å®¢è§‚çš„è´¨é‡è¯„ä¼°ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿäº†è§£åˆ†æç»“æœçš„å¯ä¿¡åº¦

**ğŸ“Š Quality Scoring Algorithm** (0-100åˆ†åˆ¶):

```python
# å››ç»´åº¦è¯„åˆ†æ¨¡å‹
dimension_weights = {
    "node_integrity": 0.40,      # èŠ‚ç‚¹å¼•ç”¨å®Œæ•´æ€§ (40%)
    "scenario_coverage": 0.30,   # ä¸šåŠ¡åœºæ™¯è¦†ç›–åº¦ (30%)
    "complexity_consistency": 0.20,  # å¤æ‚åº¦ä¸€è‡´æ€§ (20%)
    "data_extraction": 0.10      # æ•°æ®æå–æ­£ç¡®æ€§ (10%)
}

# 1. Node Integrity Score (40åˆ†)
valid_edges = count(edges where source AND target exist in nodes)
total_edges = count(all edges)
node_integrity_score = (valid_edges / total_edges) * 40

# 2. Scenario Coverage Score (30åˆ†)
scenarios_in_stage1 = count(core_business_scenarios from Stage 1)
scenarios_in_buttons = count(matching launch_buttons in Stage 3)
scenario_coverage_percentage = (scenarios_in_buttons / scenarios_in_stage1) * 100
scenario_coverage_score = (scenario_coverage_percentage / 100) * 30

# 3. Complexity Consistency Score (20åˆ†)
complexity_warnings = count(consistency warnings from Sub-Step 6.3)
complexity_consistency_score = max(0, 20 - (complexity_warnings * 5))

# 4. Data Extraction Score (10åˆ†)
data_validations = [
    nodes.length >= 10,
    edges.length >= 5,
    execution_traces.length > 0,
    core_business_scenarios.length >= 3,
    tech_stack !== undefined
]
passed_validations = count(validations that pass)
data_extraction_score = (passed_validations / 5) * 10

# Total Quality Score
total_score = (
    node_integrity_score +
    scenario_coverage_score +
    complexity_consistency_score +
    data_extraction_score
)
```

**ğŸ“ Quality Grade System**:
```
A+ (90-100åˆ†): å“è¶Šè´¨é‡ï¼Œåˆ†æç»“æœé«˜åº¦å¯ä¿¡
A  (80-89åˆ†):  ä¼˜ç§€è´¨é‡ï¼Œå¯ç›´æ¥ç”¨äºç”Ÿäº§å†³ç­–
B  (70-79åˆ†):  è‰¯å¥½è´¨é‡ï¼Œå»ºè®®å±€éƒ¨éªŒè¯åä½¿ç”¨
C  (60-69åˆ†):  åŠæ ¼è´¨é‡ï¼Œéœ€è¦é‡ç‚¹éªŒè¯å…³é”®éƒ¨åˆ†
D  (<60åˆ†):    è´¨é‡ä¸è¶³ï¼Œå»ºè®®é‡æ–°åˆ†æ
```

**ğŸ¯ Quality-Based Recommendations**:
```python
if total_score >= 90:
    recommendation = "åˆ†æè´¨é‡å“è¶Šï¼Œå¯ç›´æ¥ç”¨äºæ¶æ„å†³ç­–å’Œæ€§èƒ½ä¼˜åŒ–"
elif total_score >= 80:
    recommendation = "åˆ†æè´¨é‡ä¼˜ç§€ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨ä½è¯„åˆ†ç»´åº¦"
elif total_score >= 70:
    recommendation = "åˆ†æè´¨é‡è‰¯å¥½ï¼Œå»ºè®®éªŒè¯Nodeå¼•ç”¨å®Œæ•´æ€§åä½¿ç”¨"
elif total_score >= 60:
    recommendation = "åˆ†æè´¨é‡åŠæ ¼ï¼Œå»ºè®®é‡æ–°æ£€æŸ¥Stage 1-2çš„æ•°æ®è´¨é‡"
else:
    recommendation = "åˆ†æè´¨é‡ä¸è¶³ï¼Œå»ºè®®é‡æ–°æ‰§è¡Œåˆ†ææµç¨‹"

# Dimension-specific recommendations
if node_integrity_score < 32:  # <80% of 40
    recommendations.append("âš ï¸ Nodeå¼•ç”¨å®Œæ•´æ€§è¾ƒä½ï¼Œæ£€æŸ¥Stage 2çš„èŠ‚ç‚¹å’Œè¾¹å…³ç³»")
if scenario_coverage_score < 24:  # <80% of 30
    recommendations.append("âš ï¸ ä¸šåŠ¡åœºæ™¯è¦†ç›–ä¸è¶³ï¼ŒéªŒè¯Stage 1å’ŒStage 3çš„ä¸€è‡´æ€§")
if complexity_consistency_score < 16:  # <80% of 20
    recommendations.append("âš ï¸ å¤æ‚åº¦è¯„ä¼°ä¸ä¸€è‡´ï¼Œé‡æ–°å®¡è§†æ¶æ„æ¨¡å¼è¯†åˆ«")
if data_extraction_score < 8:  # <80% of 10
    recommendations.append("âš ï¸ æ•°æ®æå–ä¸å®Œæ•´ï¼Œæ£€æŸ¥Stageé—´çš„JSONä¼ é€’")
```

**ğŸ“Š Quality Report Output**:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š åˆ†æè´¨é‡è¯„åˆ†æŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æ€»åˆ†: <total_score>/100  ç­‰çº§: <grade>

è¯„åˆ†ç»†èŠ‚:
  â€¢ Nodeå¼•ç”¨å®Œæ•´æ€§ (40%): <node_integrity_score>/40
    â””â”€ æœ‰æ•ˆå¼•ç”¨: <valid_edges>/<total_edges> (<percentage>%)

  â€¢ ä¸šåŠ¡åœºæ™¯è¦†ç›– (30%): <scenario_coverage_score>/30
    â””â”€ åœºæ™¯åŒ¹é…: <scenarios_in_buttons>/<scenarios_in_stage1> (<coverage>%)

  â€¢ å¤æ‚åº¦ä¸€è‡´æ€§ (20%): <complexity_consistency_score>/20
    â””â”€ ä¸€è‡´æ€§è­¦å‘Š: <complexity_warnings>ä¸ª

  â€¢ æ•°æ®æå–æ­£ç¡®æ€§ (10%): <data_extraction_score>/10
    â””â”€ éªŒè¯é€šè¿‡: <passed_validations>/5 é¡¹

è´¨é‡ç­‰çº§: <grade> - <grade_description>

å»ºè®®ä¼˜å…ˆè¡ŒåŠ¨:
  <recommendation>
  <dimension_recommendations>

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**âœ… Quality Scoring Benefits**:
- **å³æ—¶åé¦ˆ**: ç”¨æˆ·ç«‹å³äº†è§£åˆ†æç»“æœçš„å¯ä¿¡åº¦
- **é—®é¢˜å®šä½**: å¿«é€Ÿè¯†åˆ«æ•°æ®è´¨é‡è–„å¼±ç¯èŠ‚
- **å†³ç­–æ”¯æŒ**: åŸºäºè´¨é‡è¯„åˆ†å†³å®šæ˜¯å¦éœ€è¦é‡æ–°åˆ†æ
- **æŒç»­æ”¹è¿›**: é€šè¿‡å†å²è¯„åˆ†è¿½è¸ªåˆ†æè´¨é‡è¶‹åŠ¿

**â¡ï¸ Next**: è¿›å…¥ Step 6 Complete Output

---

**ğŸ“Š Step 6 Complete Output**:
```
âœ… Step 6 å®Œæˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ æ–‡ä»¶1 (æ‘˜è¦): frontend/public/<é¡¹ç›®åç§°>-analysis.json
   ğŸ“Š å¤§å°: <size> KB

ğŸ“„ æ–‡ä»¶2 (å‰ç«¯): frontend/public/analysis.json â­
   ğŸ“Š å¤§å°: <size> KB
   ğŸ¯ åŒ…å«å®Œæ•´ç»“æ„:
      â€¢ Nodes: <count>ä¸ª
      â€¢ Edges: <count>æ¡
      â€¢ Traces: <count>ä¸ª
   âœ… å‰ç«¯è‡ªåŠ¨åŠ è½½å°±ç»ª
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**â¡ï¸ Next**: è‡ªåŠ¨è¿›å…¥ Step 7

---

### ğŸ¨ Step 7: å¯åŠ¨å‰ç«¯ (10ç§’)

**ğŸ§  Memory Refresh**:
```
Step: 7/7 - Launch Frontend
Previous: å·²ä¿å­˜åˆ†æç»“æœ (analysis.json + <project>-analysis.json)
Goal: å¯åŠ¨å¼€å‘æœåŠ¡å™¨å¹¶æ‰“å¼€æµè§ˆå™¨
Final Step: æ˜¾ç¤ºå®Œæˆæ€»ç»“
```

**ğŸ”§ Bash Command**:
```bash
cd /d/dart/flutter/aiflow/frontend && npm run dev
```

**âš ï¸ Important Notes**:
- Frontend uses **Vite** dev server (not webpack)
- Correct command: `npm run dev` (NOT `npm start`)
- Default port: **5173** (NOT 3000)
- Browser auto-opens at `http://localhost:5173`

**ğŸ“Š Required Output**:
```
âœ… Step 6 å®Œæˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¨ Step 7/7: å¯åŠ¨å‰ç«¯å¯è§†åŒ–
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ å¯åŠ¨Viteå¼€å‘æœåŠ¡å™¨...
â³ ç­‰å¾…å°±ç»ª...
```

å®Œæˆå:
```
âœ… Step 7 å®Œæˆ
ğŸŒ æœåŠ¡å™¨: http://localhost:5173 âœ… è¿è¡Œä¸­
ğŸ¨ æµè§ˆå™¨å·²è‡ªåŠ¨æ‰“å¼€
ğŸ“„ å‰ç«¯è‡ªåŠ¨åŠ è½½: /analysis.json
```

**â¡ï¸ Next**: æ˜¾ç¤ºæœ€ç»ˆå®Œæˆæ€»ç»“

---

## ğŸ‰ å®Œæˆæ€»ç»“ï¼ˆYOU MUST DISPLAYï¼‰

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ AIFlow v2.1 æ·±åº¦åˆ†æå®Œæˆï¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š åˆ†æç»Ÿè®¡:
  âœ… Stage 1: é¡¹ç›®è®¤çŸ¥ + æ–‡æ¡£éªŒè¯
     ğŸ“š æ–‡æ¡£å¯é æ€§: <level> (<score>)
     ğŸ¯ æ ¸å¿ƒåœºæ™¯: <count>ä¸ª
     ğŸ—ï¸ æ¶æ„: <pattern> (ç½®ä¿¡åº¦: <conf>)

  âœ… Stage 2: ç»“æ„è¯†åˆ«
     ğŸŒ³ èŠ‚ç‚¹: <nodes>ä¸ª
     ğŸ”— è¾¹: <edges>æ¡

  âœ… Stage 3: è¯­ä¹‰åˆ†æ
     ğŸ”˜ æŒ‰é’®: <total> (Macro: <m>, Micro: <mic>)

  âœ… Stage 4: æ‰§è¡Œæ¨ç† + æ€§èƒ½é‡åŒ–
     â±ï¸ æ€»TCU: <total>
     ğŸ¯ å…³é”®è·¯å¾„: <critical> (<percent>%)
     ğŸ” ç“¶é¢ˆ: <count>ä¸ª
     ğŸ’¡ ä¼˜åŒ–æœºä¼š: <count>ä¸ª

  âœ… Stage 5: å¹¶å‘æ£€æµ‹
     âš ï¸ é—®é¢˜: <count> (Critical: <c>, High: <h>)
     ğŸ›¡ï¸ çº¿ç¨‹å®‰å…¨: <percent>%

ğŸ†• v2.1å¢å¼ºç‰¹æ€§:
  âœ… ğŸ“š READMEä¸€è‡´æ€§éªŒè¯
  âœ… â±ï¸ TCUæ—¶é—´é‡åŒ–
  âœ… ğŸ¯ æ ¸å¿ƒåœºæ™¯è¯†åˆ«
  âœ… ğŸ” æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
  âœ… ğŸ’¡ ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

ğŸ“„ ç»“æœæ–‡ä»¶:
  â€¢ frontend/public/<é¡¹ç›®>-analysis.json (æ‘˜è¦)
  â€¢ frontend/public/analysis.json (å‰ç«¯åŠ è½½) â­

ğŸŒ å‰ç«¯: http://localhost:5173 âœ… è¿è¡Œä¸­
â±ï¸ æ€»è€—æ—¶: <actual_duration>

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ ä¸‹ä¸€æ­¥:
  1. æµè§ˆå™¨ä¸­æ¢ç´¢äº¤äº’å¼å¯è§†åŒ–
  2. æŸ¥çœ‹æ€§èƒ½ç“¶é¢ˆå¹¶è¯„ä¼°ä¼˜å…ˆçº§
  3. æ£€æŸ¥Critical/Highçº§åˆ«å¹¶å‘é—®é¢˜
  4. åŸºäºæ ¸å¿ƒåœºæ™¯è¿›è¡Œæµ‹è¯•
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## â±ï¸ é¢„æœŸæ—¶é—´

| é¡¹ç›®è§„æ¨¡ | æ€»è€—æ—¶ |
|---------|--------|
| å°å‹ (<1K LOC) | 40-65åˆ†é’Ÿ |
| ä¸­å‹ (1-5K LOC) | 1-2å°æ—¶ |
| å¤§å‹ (5-20K LOC) | 2-4å°æ—¶ |
| è¶…å¤§å‹ (>20K LOC) | 4-8å°æ—¶ |

---

## ğŸ†• v2.1 å¢å¼ºç‰¹æ€§è¯¦è§£

### ğŸ“š 1. æ–‡æ¡£å¯é æ€§è¯„ä¼°

**ç›®æ ‡**: é¿å…è¿‡æ—¶æ–‡æ¡£è¯¯å¯¼

**è¾“å‡ºå­—æ®µ**: `documentation_reliability`
```json
{
  "overall_score": 0.85,
  "level": "high",
  "consistency_check": {
    "tech_stack": {
      "score": 0.9,
      "readme_claims": ["React 18", "TypeScript"],
      "actual_detected": ["React 18.2", "TypeScript 5.0"],
      "conflicts": []
    }
  },
  "analysis_strategy": "high_reliability"
}
```

**ç­–ç•¥é€‰æ‹©**:
- **high (â‰¥0.8)**: ä¿¡ä»»README
- **medium (0.5-0.8)**: äº¤å‰éªŒè¯
- **low (<0.5)**: å¿½ç•¥README

---

### â±ï¸ 2. TCUæ—¶é—´æˆæœ¬æ¨¡å‹

**ç›®æ ‡**: é‡åŒ–æ€§èƒ½ï¼Œè¯†åˆ«ç“¶é¢ˆ

**æ ‡å‡†å€¼**:
- **CPU**: 1-20 TCU
- **I/O**: 50-800 TCU
- **DB**: 100-500 TCU
- **Network**: 200-800 TCU

**è¾“å‡ºå­—æ®µ**: `timeline_estimation`
```json
{
  "total_tcu": 1250,
  "critical_path_tcu": 950,
  "bottlenecks": [
    {
      "event_id": "evt_002",
      "tcu_cost": 500,
      "optimization_suggestion": "æ·»åŠ ç¼“å­˜"
    }
  ]
}
```

---

### ğŸ¯ 3. æ ¸å¿ƒä¸šåŠ¡åœºæ™¯è¯†åˆ«

**ç›®æ ‡**: è¿æ¥ä»£ç ä¸ä¸šåŠ¡ä»·å€¼

**è¾“å‡ºå­—æ®µ**: `core_business_scenarios`
```json
[
  {
    "scenario_id": "user_login",
    "name": "ç”¨æˆ·ç™»å½•æµç¨‹",
    "business_value": "high",
    "complexity": 0.6
  }
]
```

**ä¸šåŠ¡ä»·å€¼**:
- **high**: æ ¸å¿ƒåŠŸèƒ½ï¼Œå½±å“æ”¶å…¥
- **medium**: é‡è¦åŠŸèƒ½
- **low**: è¾…åŠ©åŠŸèƒ½

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **æ–‡æ¡£ç»´æŠ¤**: å¯é æ€§ <0.6 æ—¶æ›´æ–°README
2. **æ€§èƒ½ä¼˜åŒ–**: ä¼˜å…ˆä¼˜åŒ– TCU >500 çš„ç“¶é¢ˆ
3. **ä¸šåŠ¡èšç„¦**: é‡ç‚¹æµ‹è¯• high value åœºæ™¯
4. **å¹¶å‘ä¼˜åŒ–**: åˆ©ç”¨ parallel_opportunities
5. **å…³é”®è·¯å¾„**: ä¼˜åŒ–å…³é”®è·¯å¾„è·æœ€å¤§æ”¶ç›Š

---

## ğŸ“š å‚è€ƒèµ„æ–™

**æç¤ºè¯ä¼˜åŒ–æŒ‡å—**:
- `.claude/prompts/README.md` - æ€»è§ˆ
- `.claude/prompts/cot-analysis-template.md` - æ¨ç†æ¨¡æ¿
- `.claude/prompts/few-shot-examples.md` - è´¨é‡ç¤ºä¾‹
- `.claude/prompts/constraint-expression-guide.md` - çº¦æŸè§„èŒƒ

**åè®®è§„èŒƒ**:
- `frontend/src/types/protocol.ts` - JSON Schemaå®šä¹‰
