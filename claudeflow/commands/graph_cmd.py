"""
å›¾è¡¨ç”Ÿæˆå‘½ä»¤å¤„ç†å™¨
"""
from pathlib import Path
from typing import Dict, Any, List

from .base import BaseCommandHandler
from core.grapher import DependencyGrapher


class GraphCommandHandler(BaseCommandHandler):
    """graphå‘½ä»¤å¤„ç†å™¨"""

    def execute(self, args: List[str]) -> Dict[str, Any]:
        """æ‰§è¡Œå›¾è¡¨ç”Ÿæˆå‘½ä»¤"""
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘  æ­£åœ¨ç”Ÿæˆä¾èµ–å…³ç³»å›¾...                               â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()

        grapher = DependencyGrapher(str(self.project_path))

        # ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„å›¾
        self.print_progress("ç”Ÿæˆè°ƒç”¨å…³ç³»å›¾", 1, 4)
        self.print_progress("åˆ†ææ¨¡å—ä¾èµ–", 2, 4)
        self.print_progress("ç”Ÿæˆç±»å±‚æ¬¡å›¾", 3, 4)
        self.print_progress("ç”Ÿæˆæ¨¡å—åœ°å›¾", 4, 4)

        generated_graphs = grapher.generate_all_graphs()

        print()
        print("âœ… ä¾èµ–å…³ç³»å›¾ç”Ÿæˆå®Œæˆ")
        print()
        print("ğŸ“Š ç”Ÿæˆçš„å›¾è¡¨:")
        for graph_type, file_path in generated_graphs.items():
            rel_path, full_path = self.format_output_path(Path(file_path))

            # ä¸ºHTMLæ–‡ä»¶æ·»åŠ æµè§ˆå™¨æ‰“å¼€æç¤º
            if file_path.endswith('.html'):
                print(f"   â€¢ {graph_type:<20} {rel_path}")
                print(f"     ğŸ’¡ åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹: file://{Path(file_path).absolute()}")
            else:
                print(f"   â€¢ {graph_type:<20} {rel_path}")

        print()
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   â€¢ åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")
        print("   â€¢ claudeflow hotspot  - è¯†åˆ«éœ€è¦é‡æ„çš„åŒºåŸŸ")

        return {
            "generated_graphs": generated_graphs
        }


class AIContextCommandHandler(BaseCommandHandler):
    """ai-contextå‘½ä»¤å¤„ç†å™¨"""

    def execute(self, args: List[str]) -> Dict[str, Any]:
        """æ‰§è¡ŒAIä¸Šä¸‹æ–‡ç”Ÿæˆå‘½ä»¤"""
        from core.analyzer import CodeAnalyzer
        import json

        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘  æ­£åœ¨ç”ŸæˆAIä¸Šä¸‹æ–‡...                                 â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()

        analyzer = CodeAnalyzer(str(self.project_path))

        self.print_progress("åˆ†æé¡¹ç›®ç»“æ„", 1, 3)
        analysis_result = analyzer.analyze_project()

        self.print_progress("æå–å…³é”®ç»„ä»¶", 2, 3)

        # ç”Ÿæˆä¸“é—¨ç”¨äº Claude çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡
        context_data = {
            "project_summary": {
                "name": self.project_path.name,
                "languages": list(analysis_result.get("languages", {}).keys()),
                "total_files": analysis_result.get("metrics", {}).get("total_files", 0),
                "code_lines": analysis_result.get("metrics", {}).get("code_lines", 0)
            },
            "structure_overview": analysis_result.get("structure", {}),
            "key_components": [],
            "dependencies": analysis_result.get("dependencies", {}),
            "context_for_claude": {
                "project_type": self._infer_project_type(analysis_result),
                "main_languages": list(analysis_result.get("languages", {}).keys())[:3],
                "complexity_level": self._assess_complexity(analysis_result),
                "recommendations": self._generate_context_recommendations(analysis_result)
            }
        }

        # æå–å…³é”®ç»„ä»¶
        for lang, lang_data in analysis_result.get("languages", {}).items():
            functions = lang_data.get("functions", [])
            classes = lang_data.get("classes", [])

            context_data["key_components"].extend([
                {"type": "function", "name": func["name"], "file": func["file"], "language": lang}
                for func in functions[:5]
            ])
            context_data["key_components"].extend([
                {"type": "class", "name": cls["name"], "file": cls["file"], "language": lang}
                for cls in classes[:5]
            ])

        self.print_progress("ç”Ÿæˆä¸Šä¸‹æ–‡æ–‡ä»¶", 3, 3)

        # ä¿å­˜ä¸Šä¸‹æ–‡æ–‡ä»¶
        output_dir = self.project_path / "claudeflow"
        output_dir.mkdir(exist_ok=True)
        context_file = output_dir / "context.json"

        with open(context_file, 'w', encoding='utf-8') as f:
            json.dump(context_data, f, indent=2, ensure_ascii=False)

        print()
        print("âœ… AIä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆ")
        print()
        rel_path, full_path = self.format_output_path(context_file)
        print(f"ğŸ“ ä¸Šä¸‹æ–‡æ–‡ä»¶: {rel_path}")
        print()
        print(f"ğŸ“Š é¡¹ç›®æ¦‚å†µ:")
        print(f"   â€¢ é¡¹ç›®ç±»å‹: {context_data['context_for_claude']['project_type']}")
        print(f"   â€¢ ä¸»è¦è¯­è¨€: {', '.join(context_data['context_for_claude']['main_languages'])}")
        print(f"   â€¢ å¤æ‚åº¦çº§åˆ«: {context_data['context_for_claude']['complexity_level']}")
        print(f"   â€¢ å…³é”®ç»„ä»¶: {len(context_data['key_components'])} ä¸ª")

        return {
            "context_data": context_data,
            "context_file": str(context_file)
        }

    def _infer_project_type(self, analysis_result: Dict[str, Any]) -> str:
        """æ¨æ–­é¡¹ç›®ç±»å‹"""
        languages = analysis_result.get("languages", {})

        if "py" in languages:
            return "Python Project"
        elif "js" in languages:
            return "JavaScript Project"
        elif "dart" in languages:
            return "Flutter/Dart Project"
        elif "java" in languages:
            return "Java Project"
        else:
            return "Multi-language Project"

    def _assess_complexity(self, analysis_result: Dict[str, Any]) -> str:
        """è¯„ä¼°é¡¹ç›®å¤æ‚åº¦"""
        metrics = analysis_result.get("metrics", {})
        total_files = metrics.get("total_files", 0)
        languages = metrics.get("languages", 0)

        if total_files > 100 and languages > 2:
            return "High"
        elif total_files > 50 or languages > 1:
            return "Medium"
        else:
            return "Low"

    def _generate_context_recommendations(self, analysis_result: Dict[str, Any]) -> list:
        """ç”Ÿæˆä¸Šä¸‹æ–‡å»ºè®®"""
        recommendations = []

        languages = analysis_result.get("languages", {})
        if len(languages) > 1:
            recommendations.append("å¤šè¯­è¨€é¡¹ç›®ï¼Œæ³¨æ„è¯­è¨€é—´çš„æ¥å£è®¾è®¡")

        hotspots = analysis_result.get("hotspots", {})
        large_files = hotspots.get("large_files", [])
        if len(large_files) > 5:
            recommendations.append("å­˜åœ¨å¤šä¸ªå¤§æ–‡ä»¶ï¼Œå»ºè®®è¿›è¡Œæ¨¡å—åŒ–é‡æ„")

        if not recommendations:
            recommendations.append("é¡¹ç›®ç»“æ„è‰¯å¥½ï¼Œç»§ç»­ä¿æŒä»£ç è´¨é‡")

        return recommendations