"""
Code2Claude å‘½ä»¤è¡Œæ¥å£

åŸºäº code2flow çš„å¢å¼ºä»£ç åˆ†æå‘½ä»¤
"""

import argparse
import sys
import json
from pathlib import Path
from typing import Optional, Dict, Any

from .core.analyzer import CodeAnalyzer
from .core.mapper import ProjectMapper
from .core.grapher import DependencyGrapher
from .core.tracker import ChangeTracker
from .core.exporter import DataExporter


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Code2Claude - åŸºäº code2flow çš„å¢å¼ºä»£ç åˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  code2claude /cc:map                    # æ˜ å°„é¡¹ç›®ç»“æ„
  code2claude /cc:sync                   # åŒæ­¥é¡¹ç›®å˜åŒ–
  code2claude /cc:context                # ç”Ÿæˆ Claude ä¸Šä¸‹æ–‡
  code2claude /cc:graph                  # ç”Ÿæˆä¾èµ–å…³ç³»å›¾
  code2claude /cc:hotspot                # è¯†åˆ«ä»£ç çƒ­ç‚¹
  code2claude /cc:impact file.py         # å½±å“åˆ†æ
  code2claude /cc:trace function_name    # è¿½è¸ªå‡½æ•°è°ƒç”¨
  code2claude /cc:snapshot               # åˆ›å»ºé¡¹ç›®å¿«ç…§
  code2claude /cc:diff snap1 snap2       # å¯¹æ¯”å¿«ç…§å·®å¼‚
  code2claude /cc:export --format json  # å¯¼å‡ºåˆ†ææ•°æ®
        """
    )

    parser.add_argument(
        'command',
        help='è¦æ‰§è¡Œçš„å‘½ä»¤'
    )

    parser.add_argument(
        'args',
        nargs='*',
        help='å‘½ä»¤å‚æ•°'
    )

    parser.add_argument(
        '-p', '--project-path',
        default='.',
        help='é¡¹ç›®è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)'
    )

    parser.add_argument(
        '--format',
        choices=['json', 'markdown', 'html', 'csv'],
        default='json',
        help='è¾“å‡ºæ ¼å¼'
    )

    parser.add_argument(
        '--output',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--language',
        choices=['py', 'js', 'rb', 'php'],
        help='æŒ‡å®šåˆ†æçš„ç¼–ç¨‹è¯­è¨€'
    )

    parser.add_argument(
        '--depth',
        type=int,
        default=3,
        help='åˆ†ææ·±åº¦ (é»˜è®¤: 3)'
    )

    parser.add_argument(
        '--days',
        type=int,
        default=30,
        help='çƒ­ç‚¹åˆ†æçš„å¤©æ•°èŒƒå›´ (é»˜è®¤: 30)'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )

    return parser


def execute_map_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæ˜ å°„å‘½ä»¤"""
    print("æ­£åœ¨æ˜ å°„é¡¹ç›®ç»“æ„...")

    mapper = ProjectMapper(project_path)

    # ç”Ÿæˆç»“æ„æ˜ å°„
    structure_map = mapper.map_project_structure()
    print(f"é¡¹ç›®ç»“æ„æ˜ å°„å®Œæˆ")

    # ç”Ÿæˆä»£ç æ˜ å°„
    code_map = mapper.map_code_structure()
    print(f"ä»£ç ç»“æ„æ˜ å°„å®Œæˆ")

    # ç”Ÿæˆäº¤äº’å¼åœ°å›¾
    interactive_map = mapper.generate_interactive_map()
    print(f"äº¤äº’å¼åœ°å›¾ç”Ÿæˆ: {interactive_map}")

    # ä¿å­˜æ˜ å°„æ–‡ä»¶
    saved_files = mapper.save_maps()
    print("æ˜ å°„æ–‡ä»¶å·²ä¿å­˜:")
    for map_type, file_path in saved_files.items():
        print(f"   {map_type}: {file_path}")

    return {
        "structure_map": structure_map,
        "code_map": code_map,
        "saved_files": saved_files
    }


def execute_sync_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡ŒåŒæ­¥å‘½ä»¤"""
    print("æ­£åœ¨åŒæ­¥é¡¹ç›®å˜åŒ–...")

    analyzer = CodeAnalyzer(project_path)

    # é‡æ–°åˆ†æé¡¹ç›®
    analysis_result = analyzer.analyze_project()
    print(f"é¡¹ç›®åˆ†æå®Œæˆ")

    # ä¿å­˜åˆ†æç»“æœ
    output_file = analyzer.save_analysis()
    print(f"åˆ†æç»“æœå·²ä¿å­˜: {output_file}")

    # æ›´æ–°æ˜ å°„
    mapper = ProjectMapper(project_path)
    mapper.save_maps()
    print(f"é¡¹ç›®æ˜ å°„å·²æ›´æ–°")

    return {
        "analysis_result": analysis_result,
        "output_file": output_file
    }


def execute_context_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œä¸Šä¸‹æ–‡ç”Ÿæˆå‘½ä»¤"""
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆ Claude ä¸Šä¸‹æ–‡...")

    analyzer = CodeAnalyzer(project_path)
    analysis_result = analyzer.analyze_project()

    # ç”Ÿæˆä¸“é—¨ç”¨äº Claude çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡
    context_data = {
        "project_summary": {
            "name": Path(project_path).name,
            "languages": list(analysis_result.get("languages", {}).keys()),
            "total_files": analysis_result.get("metrics", {}).get("total_files", 0),
            "code_lines": analysis_result.get("metrics", {}).get("code_lines", 0)
        },
        "structure_overview": analysis_result.get("structure", {}),
        "key_components": [],
        "dependencies": analysis_result.get("dependencies", {}),
        "context_for_claude": {
            "project_type": _infer_project_type(analysis_result),
            "main_languages": list(analysis_result.get("languages", {}).keys())[:3],
            "complexity_level": _assess_complexity(analysis_result),
            "recommendations": _generate_context_recommendations(analysis_result)
        }
    }

    # æå–å…³é”®ç»„ä»¶
    for lang, lang_data in analysis_result.get("languages", {}).items():
        functions = lang_data.get("functions", [])
        classes = lang_data.get("classes", [])

        # æ·»åŠ é‡è¦çš„å‡½æ•°å’Œç±»
        context_data["key_components"].extend([
            {"type": "function", "name": func["name"], "file": func["file"], "language": lang}
            for func in functions[:5]  # å‰5ä¸ªå‡½æ•°
        ])
        context_data["key_components"].extend([
            {"type": "class", "name": cls["name"], "file": cls["file"], "language": lang}
            for cls in classes[:5]  # å‰5ä¸ªç±»
        ])

    # ä¿å­˜ä¸Šä¸‹æ–‡æ–‡ä»¶
    output_dir = Path(project_path) / "code2claude"
    output_dir.mkdir(exist_ok=True)
    context_file = output_dir / "context.json"

    with open(context_file, 'w', encoding='utf-8') as f:
        json.dump(context_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… Claude ä¸Šä¸‹æ–‡å·²ç”Ÿæˆ: {context_file}")

    return {
        "context_data": context_data,
        "context_file": str(context_file)
    }


def execute_graph_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå›¾è¡¨ç”Ÿæˆå‘½ä»¤"""
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆä¾èµ–å…³ç³»å›¾...")

    grapher = DependencyGrapher(project_path)

    # ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„å›¾
    generated_graphs = grapher.generate_all_graphs()

    print("âœ… ä¾èµ–å…³ç³»å›¾ç”Ÿæˆå®Œæˆ:")
    for graph_type, file_path in generated_graphs.items():
        print(f"   {graph_type}: {file_path}")

    return {
        "generated_graphs": generated_graphs
    }


def execute_hotspot_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œçƒ­ç‚¹è¯†åˆ«å‘½ä»¤"""
    print("ğŸ”¥ æ­£åœ¨è¯†åˆ«ä»£ç çƒ­ç‚¹...")

    tracker = ChangeTracker(project_path)
    days = options.get('days', 30)

    # è¯†åˆ«çƒ­ç‚¹
    hotspots = tracker.identify_hotspots(days)

    print(f"âœ… ä»£ç çƒ­ç‚¹è¯†åˆ«å®Œæˆ (åˆ†æäº†æœ€è¿‘ {days} å¤©)")

    # æ˜¾ç¤ºæ‘˜è¦
    freq_hotspots = hotspots.get("frequency_hotspots", [])
    if freq_hotspots:
        print(f"   é¢‘ç‡çƒ­ç‚¹: {len(freq_hotspots)} ä¸ªæ–‡ä»¶")

    complex_hotspots = hotspots.get("complexity_hotspots", [])
    if complex_hotspots:
        print(f"   å¤æ‚åº¦çƒ­ç‚¹: {len(complex_hotspots)} ä¸ªæ–‡ä»¶")

    size_hotspots = hotspots.get("size_hotspots", [])
    if size_hotspots:
        print(f"   å¤§å°çƒ­ç‚¹: {len(size_hotspots)} ä¸ªæ–‡ä»¶")

    # ä¿å­˜çƒ­ç‚¹åˆ†æç»“æœ
    output_file = Path(project_path) / "code2claude" / "tracking" / "hotspots.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(hotspots, f, indent=2, ensure_ascii=False)

    print(f"âœ… çƒ­ç‚¹åˆ†æç»“æœå·²ä¿å­˜: {output_file}")

    return {
        "hotspots": hotspots,
        "output_file": str(output_file)
    }


def execute_impact_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå½±å“åˆ†æå‘½ä»¤"""
    if not args:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶è·¯å¾„")
        return {"error": "Missing file path"}

    file_path = args[0]
    print(f"ğŸ¯ æ­£åœ¨åˆ†ææ–‡ä»¶å½±å“: {file_path}")

    tracker = ChangeTracker(project_path)

    # æ‰§è¡Œå½±å“åˆ†æ
    impact_analysis = tracker.analyze_impact(file_path)

    print(f"âœ… å½±å“åˆ†æå®Œæˆ")
    print(f"   é£é™©çº§åˆ«: {impact_analysis['risk_level']}")
    print(f"   å½±å“åˆ†æ•°: {impact_analysis['impact_score']}")
    print(f"   ç›´æ¥ä¾èµ–: {len(impact_analysis['direct_dependencies'])} ä¸ª")
    print(f"   ä¾èµ–æ­¤æ–‡ä»¶: {len(impact_analysis['dependent_files'])} ä¸ªæ–‡ä»¶")

    # ä¿å­˜å½±å“åˆ†æç»“æœ
    safe_filename = file_path.replace('/', '_').replace('\\', '_').replace('.', '_')
    output_file = Path(project_path) / "code2claude" / "tracking" / f"impact_{safe_filename}.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(impact_analysis, f, indent=2, ensure_ascii=False)

    print(f"âœ… å½±å“åˆ†æç»“æœå·²ä¿å­˜: {output_file}")

    return {
        "impact_analysis": impact_analysis,
        "output_file": str(output_file)
    }


def execute_trace_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå‡½æ•°è¿½è¸ªå‘½ä»¤"""
    if not args:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šè¦è¿½è¸ªçš„å‡½æ•°å")
        return {"error": "Missing function name"}

    function_name = args[0]
    file_path = args[1] if len(args) > 1 else None

    print(f"ğŸ” æ­£åœ¨è¿½è¸ªå‡½æ•°è°ƒç”¨: {function_name}")

    tracker = ChangeTracker(project_path)

    # æ‰§è¡Œå‡½æ•°è¿½è¸ª
    trace_result = tracker.trace_function_calls(function_name, file_path)

    print(f"âœ… å‡½æ•°è¿½è¸ªå®Œæˆ")
    print(f"   è°ƒç”¨é“¾æ·±åº¦: {trace_result['complexity']['depth']}")
    print(f"   è°ƒç”¨å¹¿åº¦: {trace_result['complexity']['breadth']}")
    print(f"   æ€»å‡½æ•°æ•°: {trace_result['complexity']['total_functions']}")

    # ä¿å­˜è¿½è¸ªç»“æœ
    output_file = Path(project_path) / "code2claude" / "tracking" / f"trace_{function_name}.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(trace_result, f, indent=2, ensure_ascii=False)

    print(f"âœ… è¿½è¸ªç»“æœå·²ä¿å­˜: {output_file}")

    return {
        "trace_result": trace_result,
        "output_file": str(output_file)
    }


def execute_snapshot_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå¿«ç…§åˆ›å»ºå‘½ä»¤"""
    snapshot_name = args[0] if args else None

    print("æ­£åœ¨åˆ›å»ºé¡¹ç›®å¿«ç…§...")

    tracker = ChangeTracker(project_path)

    # åˆ›å»ºå¿«ç…§
    snapshot_file = tracker.create_snapshot(snapshot_name)

    print(f"é¡¹ç›®å¿«ç…§å·²åˆ›å»º: {snapshot_file}")

    return {
        "snapshot_file": snapshot_file
    }


def execute_diff_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå¿«ç…§å¯¹æ¯”å‘½ä»¤"""
    if len(args) < 2:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šä¸¤ä¸ªå¿«ç…§æ–‡ä»¶è¿›è¡Œå¯¹æ¯”")
        return {"error": "Missing snapshot files"}

    snapshot1 = args[0]
    snapshot2 = args[1]

    print(f"ğŸ” æ­£åœ¨å¯¹æ¯”å¿«ç…§: {snapshot1} vs {snapshot2}")

    tracker = ChangeTracker(project_path)

    # å¯¹æ¯”å¿«ç…§
    comparison = tracker.compare_snapshots(snapshot1, snapshot2)

    print(f"âœ… å¿«ç…§å¯¹æ¯”å®Œæˆ")
    print(f"   æ€»å˜æ›´æ•°: {comparison['summary']['total_changes']}")
    print(f"   æ–°å¢æ–‡ä»¶: {len(comparison['file_changes']['added'])}")
    print(f"   åˆ é™¤æ–‡ä»¶: {len(comparison['file_changes']['deleted'])}")
    print(f"   ä¿®æ”¹æ–‡ä»¶: {len(comparison['file_changes']['modified'])}")

    # ä¿å­˜å¯¹æ¯”ç»“æœ
    output_file = Path(project_path) / "code2claude" / "tracking" / "comparison.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)

    print(f"âœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜: {output_file}")

    return {
        "comparison": comparison,
        "output_file": str(output_file)
    }


def execute_export_command(project_path: str, args: list, options: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæ•°æ®å¯¼å‡ºå‘½ä»¤"""
    export_format = options.get('format', 'json')

    print(f"ğŸ“¤ æ­£åœ¨å¯¼å‡ºæ•°æ® (æ ¼å¼: {export_format})...")

    # è·å–æœ€æ–°çš„åˆ†ææ•°æ®
    analyzer = CodeAnalyzer(project_path)
    analysis_data = analyzer.analyze_project()

    # å¯¼å‡ºæ•°æ®
    exporter = DataExporter(project_path)
    exported_files = exporter.export_analysis_data(analysis_data, [export_format])

    print(f"âœ… æ•°æ®å¯¼å‡ºå®Œæˆ:")
    for format_type, file_path in exported_files.items():
        print(f"   {format_type}: {file_path}")

    # å¦‚æœå¯¼å‡ºä¸º HTMLï¼Œè¿˜ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    if export_format == 'html':
        mapper = ProjectMapper(project_path)
        map_data = mapper.map_project_structure()

        grapher = DependencyGrapher(project_path)
        graph_data = grapher.generate_all_graphs()

        report_file = exporter.export_project_report(
            analysis_data, map_data, graph_data
        )
        print(f"   ç»¼åˆæŠ¥å‘Š: {report_file}")
        exported_files['comprehensive_report'] = report_file

    return {
        "exported_files": exported_files
    }


def _infer_project_type(analysis_result: Dict[str, Any]) -> str:
    """æ¨æ–­é¡¹ç›®ç±»å‹"""
    languages = analysis_result.get("languages", {})

    if "py" in languages:
        return "Python Project"
    elif "js" in languages:
        return "JavaScript Project"
    elif "dart" in languages:
        return "Flutter/Dart Project"
    elif "java" in languages:
        return "Java Project"
    else:
        return "Multi-language Project"


def _assess_complexity(analysis_result: Dict[str, Any]) -> str:
    """è¯„ä¼°é¡¹ç›®å¤æ‚åº¦"""
    metrics = analysis_result.get("metrics", {})
    total_files = metrics.get("total_files", 0)
    languages = metrics.get("languages", 0)

    if total_files > 100 and languages > 2:
        return "High"
    elif total_files > 50 or languages > 1:
        return "Medium"
    else:
        return "Low"


def _generate_context_recommendations(analysis_result: Dict[str, Any]) -> list:
    """ç”Ÿæˆä¸Šä¸‹æ–‡å»ºè®®"""
    recommendations = []

    languages = analysis_result.get("languages", {})
    if len(languages) > 1:
        recommendations.append("å¤šè¯­è¨€é¡¹ç›®ï¼Œæ³¨æ„è¯­è¨€é—´çš„æ¥å£è®¾è®¡")

    hotspots = analysis_result.get("hotspots", {})
    large_files = hotspots.get("large_files", [])
    if len(large_files) > 5:
        recommendations.append("å­˜åœ¨å¤šä¸ªå¤§æ–‡ä»¶ï¼Œå»ºè®®è¿›è¡Œæ¨¡å—åŒ–é‡æ„")

    if not recommendations:
        recommendations.append("é¡¹ç›®ç»“æ„è‰¯å¥½ï¼Œç»§ç»­ä¿æŒä»£ç è´¨é‡")

    return recommendations


def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()

    project_path = Path(args.project_path).resolve()

    if not project_path.exists():
        print(f"é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        sys.exit(1)

    # å‡†å¤‡é€‰é¡¹å­—å…¸
    options = {
        'format': args.format,
        'output': args.output,
        'language': args.language,
        'depth': args.depth,
        'days': args.days,
        'verbose': args.verbose
    }

    # æ‰§è¡Œå‘½ä»¤
    command = args.command.lower()
    command_args = args.args

    try:
        if command in ['/cc:map', 'map']:
            result = execute_map_command(str(project_path), command_args, options)
        elif command in ['/cc:sync', 'sync']:
            result = execute_sync_command(str(project_path), command_args, options)
        elif command in ['/cc:context', 'context']:
            result = execute_context_command(str(project_path), command_args, options)
        elif command in ['/cc:graph', 'graph']:
            result = execute_graph_command(str(project_path), command_args, options)
        elif command in ['/cc:hotspot', 'hotspot']:
            result = execute_hotspot_command(str(project_path), command_args, options)
        elif command in ['/cc:impact', 'impact']:
            result = execute_impact_command(str(project_path), command_args, options)
        elif command in ['/cc:trace', 'trace']:
            result = execute_trace_command(str(project_path), command_args, options)
        elif command in ['/cc:snapshot', 'snapshot']:
            result = execute_snapshot_command(str(project_path), command_args, options)
        elif command in ['/cc:diff', 'diff']:
            result = execute_diff_command(str(project_path), command_args, options)
        elif command in ['/cc:export', 'export']:
            result = execute_export_command(str(project_path), command_args, options)
        else:
            print(f"é”™è¯¯: æœªçŸ¥å‘½ä»¤: {command}")
            parser.print_help()
            sys.exit(1)

        if options['verbose'] and result:
            print("\nè¯¦ç»†ç»“æœ:")
            print(json.dumps(result, indent=2, ensure_ascii=False, default=str))

    except Exception as e:
        print(f"æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        if options['verbose']:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()